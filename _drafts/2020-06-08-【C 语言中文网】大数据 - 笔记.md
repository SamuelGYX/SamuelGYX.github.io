---
layout: post
title:  【C 语言中文网】大数据 - 笔记
date:   2020-06-08
categories: 大数据
---

## 第一部分 概览

### 1. 意义

#### 1. 简介

- 大数据是指无法在有限时间内用常规软件工具对其进行获取、存储、管理和处理的数据集合
- Volume、Velocity、Variety 和 Value 四个特征，即体量巨大、速度快、类型繁多和价值密度低

#### 2. 时代

- 从宏观上看，由于大数据革命的系统性影响和深远意义，主要大国快速做出战略响应，将大数据置于非常核心的位置，推出国家级创新战略计划
- 从微观上看，大数据重塑了企业的发展战略和转型方向

#### 3. 产生和作用

- 产生
  - 运营式系统阶段，被动产生
  - 用户原创内容阶段，主动产生
  - 感知式系统阶段，自动产生
- 作用
  - 对大数据的处理分析正成为新一代信息技术融合应用的<u>结点</u>
  - 大数据是信息产业持续高速增长的新<u>引擎</u>
  - 大数据利用将成为提高核心竞争力的关键因素
  - 大数据时代，科学研究的方法手段将发生重大改变

#### 4. 重大变化

1. 研究范式
2. 数据重要性
3. 方法论
4. 数据分析
5. 计算智能
6. 管理目标
7. 决策方式
8. 产业竞合关系
9. 对数据复杂性的认识
10. 数据处理模式



### 2. 基本方法

#### 5. 基本流程

- 数据抽取与集成
  - 基于物化或 ETL 方法的引擎
  - 基于联邦数据库或中间件方法的引擎
  - 基于数据流方法的引擎
  - 以及基于搜索引擎的方法
- 数据分析
  - 数据量大并不一定意味着数据价值的增加，相反这往往意味着数据噪音的增多
  - 大数据时代的算法需要进行调整
  - 数据结果的衡量标准
- 数据解释
  - 引入可视化技术
  - 让用户能够在一定程度上了解和参与具体的分析过程

#### 6. 关键技术

- 采集《[7. 大数据采集技术概述](http://c.biancheng.net/view/3526.html)》
  - 来源
    - 运营数据库
    - 社交网络
    - 感知设备
- 预处理《[11. 大数据预处理架构和方法](http://c.biancheng.net/view/3544.html)》
  - 步骤
    - 数据清理
    - 数据集成和变换
    - 数据规约
- 存储及管理
  - 用存储器把采集到的数据存储起来，建立相应的数据库，并进行管理和调用
  - 分布式存储技术
    - 分布式文件系统：非结构化数据，GFS《[Hadoop HDFS分布式文件系统](http://c.biancheng.net/view/3569.html)》
    - NoSQL 数据库系统：半结构化，BigTable，Dynamo，MongoDB《[NoSQL非关系型数据库](http://c.biancheng.net/view/3581.html)》
    - 数据仓库系统：结构化数据，Hive
- 处理
  - 批处理模式
    - MapReduce《[Hadoop MapReduce概述](http://c.biancheng.net/view/3604.html)》
    - 将问题分而治之，把待处理的数据分成多个模块分别交给多个 Map 任务去并发处理
    - 把计算推到数据而不是把数据推到计算，从而有效地避免数据传输过程中产生的大量通信开销
  - 流处理模式
    - Spark《[Spark简介](http://c.biancheng.net/view/3642.html)》《[Spark Streaming简介](http://c.biancheng.net/view/3658.html)》
- 分析及挖掘《[数据挖掘分析](http://c.biancheng.net/view/3675.html)》
  - 常用算法
    - 分类
    - 回归分析
    - 聚类
    - 关联规则
- 大数据展示
  - 数据可视化



## 第二部分 采集与预处理

### 3. 采集

#### 7. 简介

- 不但数据源的种类多，数据的类型繁杂，数据量大，并且产生的速度快，传统的数据采集方法完全无法胜任
- 分类
  - 数据类型
    - 业务数据
    - 行业数据
    - 内容数据【新】
    - 线上行为数据【新】
    - 线下行为数据【新】
  - 数据来源
    - 企业系统
    - 机器系统【新】
    - 互联网系统【新】
    - 社交系统【新】
- 采集方法
  - 数据库采集
  - 系统日志采集《[8. 系统日志采集方法](http://c.biancheng.net/view/3527.html)》
  - 网络数据采集《[9. 网络数据采集方法](http://c.biancheng.net/view/3530.html)》
  - 感知设备数据采集

#### 8. 日志系统采集

- 目前使用最广泛的、用于系统日志采集的海量数据采集工具有 Hadoop 的 Chukwa、Apache 的 Flume、Facebook 的 Scribe 和 LinkedIn 的 Kafka 等
- Flume
  - Flume 的核心是把数据从数据源（Source）收集过来，再将收集到的数据送到指定的目的地（Sink）
  - Flume 的用法很简单，主要是编写一个用户配置文件。在配置文件当中描述 Source、Channel 与 Sink 的具体实现，而后运行一个 Agent 实例

#### 9. 网络数据采集

- 网络数据采集是指通过网络爬虫或网站公开 API 等方式从网站上获取数据信息
- 网络爬虫工具分类
  - 分布式网络爬虫工具，如 Nutch
  - [Java](http://c.biancheng.net/java/) 网络爬虫工具，如 Crawler4j、WebMagic、WebCollector
  - 非 Java 网络爬虫工具，如 Scrapy(基于 [Python](http://c.biancheng.net/python/) 语言开发)
- 网页间关系模型
  - 彼此关联、庞大复杂的有向图
- 网页分类
  - 已下载未过期网页、已下载已过期网页
  - 待下载网页
  - 可知网页
  - 不可知网页
- 抓取策略
  - 通用网络爬虫（全网爬虫）
    - 深度优先策略
    - 广度优先策略
  - 聚焦网络爬虫（主题网络爬虫）
    - 基于内容评价的爬行策略：Shark Search 算法
    - 基于链接结构评价的爬行策略：PageRank 算法
    - 基于增强学习的爬行策略
    - 基于语境图的爬行策略
  - 增量式网络爬虫
    - 对已下载网页采取增量式更新并且只爬行新产生的或者已经发生变化网页的爬虫
  - 深层网络爬虫
    - 深层网页是那些大部分内容不能通过静态链接获取的，隐藏在搜索表单后的，只有用户提交一些关键词才能获得的网页

#### 10. Scrapy 网络爬虫

- Scrapy 是一个为了爬取网站数据、提取结构性数据而编写的应用框架
- Scrapy 的整体架构由 Scrapy 引擎（ScrapyEngine）、调度器（Scheduler）、下载器（Downloader）、爬虫（Spiders）和数据项管道（itemPipeline）5 个组件组成



### 4. 预处理

#### 11. 简介

- 数据预处理主要包括数据清洗（Data Cleaning）、数据集成（Data Integration）、数据转换（Data Transformation）和数据消减（Data Reduction）
- 结构化数据
  - 传统 ETL 工具
  - 传统的关系型数据库
  - 关系型数据库在处理事务、及时响应、保证数据的一致性方面有天然的优势
- 半结构化/非结构化数据
  - 分布式并行处理框架
  - 半结构化：分布式 [NoSQL](http://c.biancheng.net/nosql/) 数据库中，如 [HBase](http://c.biancheng.net/hbase/)
  - 非结构化：新型的分布式存储中，如 Hadoop 的 HDFS
  - 分布式存储在系统的横向扩展性、存储成本、文件读取速度方面有着显著的优势
- 数据质量问题

#### 12. 数据清洗

- 现实世界的数据常常是不完全的、有噪声的、不一致的
- 主要方法
  1. 遗漏数据处理
  2. 噪声数据处理
     1. Bin 方法
     2. 聚类分析方法
     3. 人机结合检查方法
     4. 回归方法
  3. 不一致数据处理

#### 13. 数据集成

- 将来自多个数据源的数据，如数据库、数据立方、普通文件等，结合在一起并形成一个统一数据集合，以便为数据处理工作的顺利完成提供完整的数据基础
- 问题
  - 模式集成问题
  - 冗余问题
  - 数据值冲突检测与消除问题：单位，编码不一致

#### 14. 数据转换

- 将数据进行转换或归并，从而构成一个适合数据处理的描述形式
- 主要方法
  1. 平滑处理：即噪声数据处理
  2. 合计处理
  3. 数据泛化处理
  4. 规格化处理
     - 将一个属性取值范围投射到一个特定范围之内
  5. 属性构造处理
     - 根据已有属性集构造新的属性

#### 15. 数据消减

- 从原有巨大数据集中获得一个精简的数据集，并使这一精简数据集保持原有数据集的完整性
- 主要方法
  1. 数据立方合计
  2. 维数消减
     - 只保留有用的属性
  3. 数据压缩
     - 离散小波转换（Discrete Wavelet Transforms）
     - 主要素分析（Principal Components Analysis）
  4. 数据块消减
     - 回归与线性对数模型
     - 直方图
     - 聚类
     - 采样
  5. 离散化与概念层次生成

#### 16. 离散化和数值概念层次树

- 离散化技术方法可以通过将属性（连续取值）域值范围分为若干区间，来帮助消减一个连续（取值）属性的取值个数
- 数值概念层次树
  - Bin 方法
  - 直方图方法
  - 聚类分析方法
  - 基于熵的方法
  - 自然划分分段方法
- 类别概念层次树
  - 类别数据是一种离散数据。类别属性可取有限个不同的值且这些值之间无大小和顺序，如国家、工作、商品类别等
  - 一个重要线索就是，高层次概念通常包含了若干低层次概念。定义属性的高层次概念通常比低层次概念包含少一些的不同值



## 第三部分 处理

### 5. 概览

#### 17. 简介

- 分布式计算
- 服务器集群
- 大数据的技术基础
  - MapReduce 是分布式计算框架，GFS 是分布式文件系统，BigTable 是基于 GFS 的数据存储系统，这 3 大组件组成了 Google 的分布式计算模型
  - MapReduce：针对大规模群组中的海量数据处理的分布式计算框架，解决如何从海量数据中快速计算并获取期望结果的问题
  - GFS：大型的分布式文件系统，处于系统的底层，解决海量数据的存储问题
  - BigTable：基于 GFS 的数据存储系统，大规模分布式数据存储系统，是用来处理海量数据的一种非关系型数据库

| 大数据系统体系 | 计算框架         | 文件系统 | 数据存储系统 |
| -------------- | ---------------- | -------- | ------------ |
| Hadoop 体系    | Hadoop MapReduce | HDFS     | HBase        |
| Google 体系    | MapReduce        | GFS      | BigTable     |

#### 18. Google 系统

- GFS
  - 主要由一个 Master Server（主服务器）和多个 Chunk Server（数据块服务器）组成
  - 优势
    - Client 和 Master Server 之间只有控制流，没有数据流，因此降低了 Master Server 的负载
    - 由于 Client 与 Chunk Server 之间直接传输数据流，并且文件被分成多个 Chunk 进行分布式存储，因此 Client 可以同时并行访问多个 Chunk Server，从而让系统的 I/O 并行度提高
  - 特点
    - 采用中心服务器模式
    - 不缓存数据
- MapReduce
  - Map：把一个函数应用于集合中的所有成员，然后返回一个基于这个处理的结果集
  - Reduce：把两个或更多个 Map 通过多个线程、进程或者独立系统进行并行执行处理得到的结果集进行分类和归纳
- BigTable
  - 需要存储的数据种类繁多
  - 海量的服务请求
  - 商用数据库无法满足 Google 的需求

#### 19. [Hadoop大数据处理框架](http://c.biancheng.net/view/3568.html)

- 一个基础框架，允许用简单的编程模型在计算机集群上对大型数据集进行分布式处理

1）HDFS（GFS）：一个提供高可用的获取应用数据的分布式文件系统。

2）MapReduce：一个并行处理大数据集的编程模型。

3）HBase（BigTable）：一个可扩展的分布式数据库，支持大表的结构化数据存储。是一个建立在 HDFS 之上的，面向列的 [NoSQL](http://c.biancheng.net/nosql/) 数据库，用于快速读/写大量数据。

4）Hive：一个建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具；可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。 Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许不熟悉 MapReduce 的开发人员也能编写数据查询语句，然后这些语句被翻译为 Hadoop 上面的 MapReduce 任务。

5）Mahout：可扩展的机器学习和数据挖掘库。它提供的 MapReduce 包含很多实现方法，包括聚类算法、回归测试、统计建模。

6）Pig：一个支持并行计算的高级的数据流语言和执行框架。它是 MapReduce 编程的复杂性的抽象。Pig 平台包括运行环境和用于分析 Hadoop 数据集的脚本语言（PigLatin）。其编译器将 PigLatin 翻译成 MapReduce 程序序列。

7）Zookeeper：—个应用于分布式应用的高性能的协调服务。它是一个为分布式应用提供一致性服务的软件，提供的功能包括配置维护、域名服务、分布式同步、组服务等。

8）Amban：一个基于 Web 的工具，用来供应、管理和监测 Hadoop 集群，包括支持 HDFS、MapReduceAHive、HCatalog、HBase、ZooKeeperAOozie、Pig 和 Sqoop 。Ambari 也提供了一个可视的仪表盘来查看集群的健康状态，并且能够使用户可视化地查看 MapReduce、Pig 和 Hive 应用来诊断其性能特征。

### 6. HDFS（GFS 的开源实现）

#### 20. [HDFS](http://c.biancheng.net/view/3569.html)

- 分布式文件系统是一种允许文件通过网络在多台主机上进行分享的文件系统，可让多台机器上的多用户分享文件和存储空间
- 在 HDFS 体系结构中有两类结点：一类是 NameNode，又叫“名称结点”；另一类是 DataNode，又叫“数据结点”。这两类结点分别承担 Master 和 Worker 具体任务的执行
- HDFS 是一个主/从体系结构，从最终用户的角度来看，它就像传统的文件系统一样，可以通过目录路径对文件执行 CRUD（Create、Read、Update 和 Delete）操作
- HDFS 主要针对“一次写入，多次读取”的应用场景，不适合实时交互性很强的应用场景，也不适合存储大量小文件

#### 21. [HDFS基本原理和设计理念](http://c.biancheng.net/view/3570.html)

- 文件系统是操作系统提供的磁盘空间管理服务，该服务只需要用户指定文件的存储位置及文件读取路径，而不需要用户了解文件在磁盘上是如何存放的
- HDFS 的基本思想
  - 为了解决存储结点负载不均衡的问题，HDFS 首先把一个文件分割成多个块，然后再把这些文件块存储在不同服务器上
  - 为了保证文件的可靠性，HDFS 会把每个文件块进行多个备份，一般情况下是 3 个备份
  - 采用分块多副本存储方式后，HDFS 文件的可靠性就大大增强了，即使某个服务器出现故障，也仍然可以完整读取文件，该方式同时还带来一个很大的好处，就是增加了文件的并发访问能力
  - 为了管理文件，HDFS 需要记录维护一些元数据，也就是关于文件数据信息的数据，如 HDFS 中存了哪些文件，文件被分成了哪些块，每个块被放在哪台服务器上等
  - HDFS 把这些元数据抽象为一个目录树，来记录这些复杂的对应关系。这些元数据由一个单独的模块进行管理，这个模块叫作名称结点（NameNode）。存放文件块的真实服务器叫作数据结点（DataNode）
- HDFS 的设计理念
  - 可以运行在普通机器上，以流式数据方式存储文件，一次写入、多次查询
  - 可构建在廉价机器上
  - 高容错性
  - 适合批处理
  - 适合存储大文件
- HDFS 的局限
  - 实时性差
  - 小文件问题：每个文件、目录和数据块的存储信息大约占 150 字节，过多的小文件存储会大量消耗 NameNode 的存储量
  - 文件修改问题：HDFS 中的文件只有一个写入者，而且写操作总是将数据添加在文件的末尾。HDFS 不支持具有多个写入者的操作，也不支持在文件的任意位置进行修改

#### 22. [HDFS架构和实现机制](http://c.biancheng.net/view/3571.html)

- 整体架构
  - HDFS 是一个主从 Master/Slave 架构。一个 HDFS 集群包含一个 NameNode，这是一个 Master  Server，用来管理文件系统的命名空间，以及调节客户端对文件的访问。一个 HDFS 集群还包括多个 DataNode，用来存储数据
  - NameNode
    - 文件的元数据采用集中式存储方案存放在 NameNode 当中。NameNode 负责执行文件系统命名空间的操作，如打幵、关闭、重命名文件和目录。NameNode 同时也负责将数据块映射到对应的 DataNode 中
  - DataNode
    - DataNode 是文件系统的工作结点。它们根据需要存储并检索数据块，并且定期向 NameNode 发送他们所存储的块的列表
  - Client

- 数据复制
  - NameNode 控制所有的数据块的复制决策
  - 通用场景下，当复制因子是 3 时，HDFS 的放置策略是将一个副本放置到本地机架的一个结点上，另一个放在本地机架的不同结点上，最后一个放在不同机架的不同结点上
  - 当一切运行正常时，DataNode 会周期性发送心跳信息给 NameNode（默认是每 3 秒钟一次）。如果 NameNode  在预定的时间内没有收到心跳信息（默认是 10 分钟），就会认为 DataNode 出现了问题，这时候就会把该 DataNode  从集群中移除，并且启动一个进程去恢复数据

#### 23. [HDFS读取和写入数据](http://c.biancheng.net/view/3574.html)

- 读取流程
- 写入流程

#### 24. [HDFS两种操作方式](http://c.biancheng.net/view/3576.html)

- 命令行
- Java API



### 7. HBase（BigTable 的开源实现）

#### 25. [NoSQL简介](http://c.biancheng.net/view/3581.html)

- 易扩展、大数据量和高性能及灵活的数据模型
- 起因
  - 无法满足对海量数据的高效率**<u>存储</u>**和<u>**访问**</u>的需求
  - 无法满足对数据库的高可扩展性和高可用性的需求
  - 关系数据库无法存储和处理<u>**半结构化/非结构化**</u>数据
  - 关系数据库的**<u>事务特性</u>**对 Web 2.0 是不必要的
  - Web 2.0 无须进行复杂的 SQL 查询，特别是**<u>多表关联查询</u>**
- 特点
  - 灵活的可扩展性：去掉了关系型数据库的关系型裝性，数据之间无关系，非常容易扩展，从而也在架构层面上带来了可横向扩展的能力
  - 大数据量和高性能：得益于 NoSQL 数据库的无关系性
  - 灵活的数据模型，可以处理半结构化/非结构化的大数据
- 问题
  - 成熟度
  - 支持：大多数 NoSQL 系统都是开源项目
  - 分析与商业智能：缺少即席查询和数据分析工具，即便是一个简单的查询都需要专业的编程技能
  - 管理
  - 专业：专业人员不足

#### 26. [NoSQL类型简介](http://c.biancheng.net/view/3594.html)

- 键值数据库
  - 键值数据库起源于 Amazon 开发的 Dynamo 系统，可以把它理解为一个分布式的 Hashmap，支持 SET/GET 元操作
  - 在存在大量写操作的情况下，键值数据库可以比关系数据库有明显的性能优势
  - 分类
    - 内存键值数据库：把数据保存在内存中，Memcached 和 [Redis](http://c.biancheng.net/redis/)
    - 持久化键值数据库：把数据保存在磁盘中，BerkeleyDB、Voldmort 和 Riak
  - 键值数据库也有自身的局限性，主要是条件查询。如果只对部分值进行查询或更新，效率会比较低下。在使用键值数据库时，应该尽量避免多表关联查询。此外，键值数据库在发生故障时不支持回滚操作，所以无法支持事务
- 列式数据库
  - 列式数据库起源于 Google 的 BigTable，其数据模型可以看作是一个每行列数可变的数据表
- 文档数据库
  - 文档数据库是通过键来定位一个文档的，所以是键值数据库的一种衍生品。在文档数据库中，文档是数据库的最小单位
  - 文档数据库既可以根据键来构建索引，也可以基于文档内容来构建索引。基于文档内容的索引和查询能力是文档数据库不同于键值数据库的主要方面，因为在键值数据库中，值对数据库是透明不可见的，不能基于值构建索引
  - 从关系型数据库存储方式的角度来看，每一个事物都应该存储一次，并且通过外键进行连接，而文件存储不关心规范化，只要数据存储在一个有意义的结构中就可以。
- 图形数据库
  - 图形数据库是 NoSQL 数据库类型中最复杂的一个，旨在以高效的方式存储实体之间的关系
  - 典型的图形数据库有 Neo4J、OrientDB、InfoGrid、Infinite Graph 和 GraphDB 等

#### 27. [HBase简介](http://c.biancheng.net/view/3584.html)

- [HBase](http://c.biancheng.net/hbase/) 是基于 Apache Hadoop 的面向列的 [NoSQL](http://c.biancheng.net/nosql/) 数据库，是 Google 的 BigTable 的开源实现
- HBase 和传统关系数据库不同，它采用了 BigTable 的数据模型增强的稀疏排序映射表（Key/Value），其中，键由<u>**行关键字、列关键字和时间戳**</u>构成
- Hadoop 是一个高容错、高延时的分布式文件系统和高并发的批处理系统，不适用于提供实时计算，而 HBase 是可以提供实时计算的分布式数据库，数据被保存在 HDFS (分布式文件系统）上，由 HDFS 保证其高容错性
- HBase 可以直接使用本地文件系统，也可以使用 Hadoop 的 HDFS。HBase 中保存的数据可以使用 MapReduce 来处理，它将数据存储和并行计算有机地结合在一起

#### 28. [HBase列式数据模型](http://c.biancheng.net/view/3586.html)

- 数据模型概述
  - HBase 是一个稀疏、多维度、有序的映射表
  - 这张表中每个单元是通过由<u>**行键、列族、列限定符和时间戳**</u>组成的索引来标识的。每个单元的值是一个未经解释的字符串，没有数据类型。当用户在表中存储数据时，每一行都有一个唯一的行键和任意多的列
  - HBase 执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，原有的版本仍然保留
  - 稀疏
    - 尽管表中的每一行会拥有相同的列族，但是可能具有截然不同的列。正因为如此，对于整个映射表的每行数据而言，有些列的值就是空的，所以 HBase 的表是稀疏的
  - 多维度
    - 行键、列族、列限定符和时间戳
  - 有序
    - 表的行是按照行键顺序来进行存储的

- 数据模型的基本概念
  - 表（Table)
  - 行（Row)
    - 设计行键的一个重要原则就是相关的行键要存储在接近的位置，例如，设计记录网站的表时，行键需要将域名反转（例如，org.apache.www、org.apache.mail、org.apache.jira），这样的设计能使与 apache 相关的域名在表中存储的位置非常接近
  - 列（Column）
    - 在定义 HBase 表的时候需要提前设置好列族，表中所有的列都需要组织在列族里面。列族一旦确定后，就不能轻易修改，因为它会影响到 HBase 真实的物理存储结构，但是列族中的列限定符及其对应的值可以动态增删
    - 列族（Column Family)：
    - 列限定符（Column Qualifier）
  - 单元（Cell）
    - 行键、列族和列限定符一起标识一个单元，存储在单元里的数据称为单元数据，没有特定的数据类型，以二进制字节来存储
  - 时间戳（Timestamp）

- 概念视图
  - 在 HBase 的概念视图中，一张表可以视为一个稀疏、多维的映射关系，通过“行键+列族:列限足符+时间戳”的格式就可以定位特定单元的数据
- 物理视图
  - 虽然从概念视图层面来看，HBase 的每个表是由许多行组成的，但是在物理存储层面来看，它是采用了基于列组的存储方式，而不是像关系型据库那样用基于行的存储方式。这正是 HBase 与关系型数据库的重要区别之一

#### 29. [HBase Shell](http://c.biancheng.net/view/3587.html)

- HBase Shell 提供了大多数的 HBase 命令，通过 HBase Shell，用户可以方便地创建、删除及修改表，还可以向表中添加数据，列出表中的相关信息等

#### 30. [HBase主要运行机制](http://c.biancheng.net/view/3598.html)

- 物理存储
  - HBase 表中的所有行都是按照行键的字典序排列的，当一张表的行太多的时候，HBase 就会根据行键的值对表中的行进行分区，每个行区间构成一个“分区（Region）”，包含了位于某个值域区间内的所有数据
  - Region 是 HBase 中数据分发和负载均衡的最小单元，默认大小是 100MB 到 200MB
  - 不同的 Region 可以分布在不同的 Region Server 上，但一个 Region 不会拆分到多个 Region Server 上。每个 Region Server 负责管理一个 Region 集合
  - Region 是 HBase 在 Region Server 上数据分发的最小单元，但并不是存储的最小单元。事实上，每个 Region  由一个或者多个 Store 组成，每个 Store 保存一个列族的数据。每个 Store 又由一个 memStore 和 0 至多个 Store File 组成。Store File 以 HFile 格式保存在 HDFS 上
- 逻辑架构
  - 在分布式的生产环境中，HBase 需要运行在 HDFS 之上，以 HDFS 作为其基础的存储设施
  -  Master
    - 表的管理工作：增加表、删除表、修改表和查询表等操作
    - Region 的管理工作：分配 Region 给 Region Server，协调多个 Region Server，检测各个 Region Server 的状态，并平衡 Region Server 之间的负载
    - HBase 允许多个 Master 结点共存，但是这需要 Zookeeper 进行协调。当多个 Master 结点共存时，只有一个 Master 是提供服务的，其他的 Master 结点处于待命的状态。当正在工作的 Master 结点宕机时，其他的 Master 则会接管 HBase  的集群
  - Region Server
    - Region Server 是 HBase 最核心的模块，负责维护 Master 分配给它的 Region 集合，并处理对这些 Region 的读写操作
    - HBase 釆用 HDFS 作为底层存储文件系统，Region Server 需要向 HDFS 写入数据，并利用 HDFS 提供可靠稳定的数据存储。Region Server 并不需要提供数据复制和维护数据副本的功能
  - Zookeeper
    - Zookeeper 保证了至少有一个 HBase Master 处于运行状态
    - Zookeeper 同时负责 Region 和 Region Server 的注册。每个 Region Server 都向 Zookeeper 注册，由 Zookeeper 实时监控每个 Region Server 的状态，并通知给 Master

### 8. MapReduce

#### 33. [Hadoop MapReduce](http://c.biancheng.net/view/3604.html)

- 批处理模式
  - 批处理模式是一种最早进行大规模数据处理的模式。批处理主要操作大规模静态数据集，并在整体数据处理完毕后返回结果。批处理非常适合需要访问整个数据集合才能完成的计算工作
  - 由于批处理在应对大量持久数据方面的表现极为出色，因此经常被用于对历史数据进行分析
  - Hadoop MapReduce 运行在 HDFS 上
- 简释
  - 如果我们想知道相当厚的一摞牌中有多少张红桃，最直观的方式就是一张张检查这些牌，并且数出有多少张是红桃
  - MapReduce 方法通过让所有玩家同时并行检查牌来找出一摞牌中有多少红桃
  - 映射（Map)：对集合中的每个元素进行同一个操作
  - 化简（Reduce)：遍历集合中的元素来返回一个综合的结果
- 基本思想
  - 大数据处理思想：分而治之
  - 构建抽象模型：Map 函数和 Reduce 函数
  - 上升到架构：并行自动化并隐藏底层细节
    - 任务调度，数据/程序互定位，出错处理，分布式数据存储与文件管理，Combiner 和 Partitioner
- Map 函数和 Reduce 函数

| 函数   | 输入          | 输出          | 注解                                                         |
| ------ | ------------- | ------------- | ------------------------------------------------------------ |
| Map    | Map<k1,V1>    | List(<k1,V2>) | 将输入数据集分解成一批<key,value>对，然后进行处理；每一个<key,value>输入，Map 会输出一批<K2,V2> |
| Reduce | <k2,List(V2)> | <K3,V3>       | MapReduce 框架会把 Map 的输出，按 key 归类为 <K2,List(V2)>。List(V2) 是一批属于同一个 K2 的 value |

#### 34. [Hadoop MapReduce架构](http://c.biancheng.net/view/3607.html)

## 第四部分 Spark

#### 39. [Spark简介](http://c.biancheng.net/view/3642.html)

- Spark 与 Hadoop
  - Hadoop MapRedcue 的缺点
    - 表达能力有限
    - 磁盘 I/O 开销大
    - 计算延迟高
  - Spark 的优势
    - Spark 提供了内存计算，把中间结果放到内存中，带来了更高的迭代运算效率
    - Spark 为我们提供了一个全面、统一的框架，用于管理各种有着不同性质（文本数据、图表数据等）的数据集和数据源（批量数据或实时的流数据）的大数据处理的需求
    - Spark 比 Hadoop 更加通用
    - Spark 基于 DAG 的任务调度执行机制比 Hadoop MapReduce 的迭代执行机制更优越
  - Spark 的问题
    - 因为 Spark 是基于内存进行数据处理的，所以不适合于数据量特别大、对实时性要求不高的场合
    - 另外，Hadoop 可以使用廉价的通用服务器来搭建集群，而 Spark 对硬件要求比较高，特别是对内存和 CPU 有更高的要求
- Spark 的适用场景
  - 大数据处理场景
    - 复杂的批量处理：MapReduce
    - 基于历史数据的交互式查询：Impala
    - 基于实时数据流的数据处理：Storm
  - 适用场景
    - Spark 是基于内存的迭代计算框架，适用于需要多次操作特定数据集的应用场合。需要反复操作的次数越多，所需读取的数据量越大，受益越大；数据量小但是计算密集度较大的场合，受益就相对较小
    - Spark 适用于数据量不是特别大，但是要求实时统计分析的场景
    - 由于 RDD 的特性，Spark 不适用于那种异步细粒度更新状态的应用，例如，Web 服务的存储，或增量的 Web 爬虫和索引，也就是不适合增量修改的应用模型

