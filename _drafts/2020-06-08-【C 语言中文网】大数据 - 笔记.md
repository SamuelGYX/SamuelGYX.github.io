---
layout: post
title:  【C 语言中文网】大数据 - 笔记
date:   2020-06-08
categories: 大数据
---

## 第一部分 概览

### 1. 意义

#### 1. 简介

- 大数据是指无法在有限时间内用常规软件工具对其进行获取、存储、管理和处理的数据集合
- Volume、Velocity、Variety 和 Value 四个特征，即体量巨大、速度快、类型繁多和价值密度低

#### 2. 时代

- 从宏观上看，由于大数据革命的系统性影响和深远意义，主要大国快速做出战略响应，将大数据置于非常核心的位置，推出国家级创新战略计划
- 从微观上看，大数据重塑了企业的发展战略和转型方向

#### 3. 产生和作用

- 产生
  - 运营式系统阶段，被动产生
  - 用户原创内容阶段，主动产生
  - 感知式系统阶段，自动产生
- 作用
  - 对大数据的处理分析正成为新一代信息技术融合应用的<u>结点</u>
  - 大数据是信息产业持续高速增长的新<u>引擎</u>
  - 大数据利用将成为提高核心竞争力的关键因素
  - 大数据时代，科学研究的方法手段将发生重大改变

#### 4. 重大变化

1. 研究范式
2. 数据重要性
3. 方法论
4. 数据分析
5. 计算智能
6. 管理目标
7. 决策方式
8. 产业竞合关系
9. 对数据复杂性的认识
10. 数据处理模式



### 2. 基本方法

#### 5. 基本流程

- 数据抽取与集成
  - 基于物化或 ETL 方法的引擎
  - 基于联邦数据库或中间件方法的引擎
  - 基于数据流方法的引擎
  - 以及基于搜索引擎的方法
- 数据分析
  - 数据量大并不一定意味着数据价值的增加，相反这往往意味着数据噪音的增多
  - 大数据时代的算法需要进行调整
  - 数据结果的衡量标准
- 数据解释
  - 引入可视化技术
  - 让用户能够在一定程度上了解和参与具体的分析过程

#### 6. 关键技术

- 采集《[7. 大数据采集技术概述](http://c.biancheng.net/view/3526.html)》
  - 来源
    - 运营数据库
    - 社交网络
    - 感知设备
- 预处理《[11. 大数据预处理架构和方法](http://c.biancheng.net/view/3544.html)》
  - 步骤
    - 数据清理
    - 数据集成和变换
    - 数据规约
- 存储及管理
  - 用存储器把采集到的数据存储起来，建立相应的数据库，并进行管理和调用
  - 分布式存储技术
    - 分布式文件系统：非结构化数据，GFS《[Hadoop HDFS分布式文件系统](http://c.biancheng.net/view/3569.html)》
    - NoSQL 数据库系统：半结构化，BigTable，Dynamo，MongoDB《[NoSQL非关系型数据库](http://c.biancheng.net/view/3581.html)》
    - 数据仓库系统：结构化数据，Hive
- 处理
  - 批处理模式
    - MapReduce《[Hadoop MapReduce概述](http://c.biancheng.net/view/3604.html)》
    - 将问题分而治之，把待处理的数据分成多个模块分别交给多个 Map 任务去并发处理
    - 把计算推到数据而不是把数据推到计算，从而有效地避免数据传输过程中产生的大量通信开销
  - 流处理模式
    - Spark《[Spark简介](http://c.biancheng.net/view/3642.html)》《[Spark Streaming简介](http://c.biancheng.net/view/3658.html)》
- 分析及挖掘《[数据挖掘分析](http://c.biancheng.net/view/3675.html)》
  - 常用算法
    - 分类
    - 回归分析
    - 聚类
    - 关联规则
- 大数据展示
  - 数据可视化



## 第二部分 采集与预处理

### 3. 采集

#### 7. 简介

- 不但数据源的种类多，数据的类型繁杂，数据量大，并且产生的速度快，传统的数据采集方法完全无法胜任
- 分类
  - 数据类型
    - 业务数据
    - 行业数据
    - 内容数据【新】
    - 线上行为数据【新】
    - 线下行为数据【新】
  - 数据来源
    - 企业系统
    - 机器系统【新】
    - 互联网系统【新】
    - 社交系统【新】
- 采集方法
  - 数据库采集
  - 系统日志采集《[8. 系统日志采集方法](http://c.biancheng.net/view/3527.html)》
  - 网络数据采集《[9. 网络数据采集方法](http://c.biancheng.net/view/3530.html)》
  - 感知设备数据采集

#### 8. 日志系统采集

- 目前使用最广泛的、用于系统日志采集的海量数据采集工具有 Hadoop 的 Chukwa、Apache 的 Flume、Facebook 的 Scribe 和 LinkedIn 的 Kafka 等
- Flume
  - Flume 的核心是把数据从数据源（Source）收集过来，再将收集到的数据送到指定的目的地（Sink）
  - Flume 的用法很简单，主要是编写一个用户配置文件。在配置文件当中描述 Source、Channel 与 Sink 的具体实现，而后运行一个 Agent 实例

#### 9. 网络数据采集

- 网络数据采集是指通过网络爬虫或网站公开 API 等方式从网站上获取数据信息
- 网络爬虫工具分类
  - 分布式网络爬虫工具，如 Nutch
  - [Java](http://c.biancheng.net/java/) 网络爬虫工具，如 Crawler4j、WebMagic、WebCollector
  - 非 Java 网络爬虫工具，如 Scrapy(基于 [Python](http://c.biancheng.net/python/) 语言开发)
- 网页间关系模型
  - 彼此关联、庞大复杂的有向图
- 网页分类
  - 已下载未过期网页、已下载已过期网页
  - 待下载网页
  - 可知网页
  - 不可知网页
- 抓取策略
  - 通用网络爬虫（全网爬虫）
    - 深度优先策略
    - 广度优先策略
  - 聚焦网络爬虫（主题网络爬虫）
    - 基于内容评价的爬行策略：Shark Search 算法
    - 基于链接结构评价的爬行策略：PageRank 算法
    - 基于增强学习的爬行策略
    - 基于语境图的爬行策略
  - 增量式网络爬虫
    - 对已下载网页采取增量式更新并且只爬行新产生的或者已经发生变化网页的爬虫
  - 深层网络爬虫
    - 深层网页是那些大部分内容不能通过静态链接获取的，隐藏在搜索表单后的，只有用户提交一些关键词才能获得的网页

#### 10. Scrapy 网络爬虫

- Scrapy 是一个为了爬取网站数据、提取结构性数据而编写的应用框架
- Scrapy 的整体架构由 Scrapy 引擎（ScrapyEngine）、调度器（Scheduler）、下载器（Downloader）、爬虫（Spiders）和数据项管道（itemPipeline）5 个组件组成



### 4. 预处理

#### 11. 简介

- 数据预处理主要包括数据清洗（Data Cleaning）、数据集成（Data Integration）、数据转换（Data Transformation）和数据消减（Data Reduction）
- 结构化数据
  - 传统 ETL 工具
  - 传统的关系型数据库
  - 关系型数据库在处理事务、及时响应、保证数据的一致性方面有天然的优势
- 半结构化/非结构化数据
  - 分布式并行处理框架
  - 半结构化：分布式 [NoSQL](http://c.biancheng.net/nosql/) 数据库中，如 [HBase](http://c.biancheng.net/hbase/)
  - 非结构化：新型的分布式存储中，如 Hadoop 的 HDFS
  - 分布式存储在系统的横向扩展性、存储成本、文件读取速度方面有着显著的优势
- 数据质量问题

#### 12. 数据清洗

- 现实世界的数据常常是不完全的、有噪声的、不一致的
- 主要方法
  1. 遗漏数据处理
  2. 噪声数据处理
     1. Bin 方法
     2. 聚类分析方法
     3. 人机结合检查方法
     4. 回归方法
  3. 不一致数据处理

#### 13. 数据集成

- 将来自多个数据源的数据，如数据库、数据立方、普通文件等，结合在一起并形成一个统一数据集合，以便为数据处理工作的顺利完成提供完整的数据基础
- 问题
  - 模式集成问题
  - 冗余问题
  - 数据值冲突检测与消除问题：单位，编码不一致

#### 14. 数据转换

- 将数据进行转换或归并，从而构成一个适合数据处理的描述形式
- 主要方法
  1. 平滑处理：即噪声数据处理
  2. 合计处理
  3. 数据泛化处理
  4. 规格化处理
     - 将一个属性取值范围投射到一个特定范围之内
  5. 属性构造处理
     - 根据已有属性集构造新的属性

#### 15. 数据消减

- 从原有巨大数据集中获得一个精简的数据集，并使这一精简数据集保持原有数据集的完整性
- 主要方法
  1. 数据立方合计
  2. 维数消减
     - 只保留有用的属性
  3. 数据压缩
     - 离散小波转换（Discrete Wavelet Transforms）
     - 主要素分析（Principal Components Analysis）
  4. 数据块消减
     - 回归与线性对数模型
     - 直方图
     - 聚类
     - 采样
  5. 离散化与概念层次生成

#### 16. 离散化和数值概念层次树

- 离散化技术方法可以通过将属性（连续取值）域值范围分为若干区间，来帮助消减一个连续（取值）属性的取值个数
- 数值概念层次树
  - Bin 方法
  - 直方图方法
  - 聚类分析方法
  - 基于熵的方法
  - 自然划分分段方法
- 类别概念层次树
  - 类别数据是一种离散数据。类别属性可取有限个不同的值且这些值之间无大小和顺序，如国家、工作、商品类别等
  - 一个重要线索就是，高层次概念通常包含了若干低层次概念。定义属性的高层次概念通常比低层次概念包含少一些的不同值



## 第三部分 Hadoop

### 5. 大数据处理技术

#### 17. 处理技术

- 分布式计算
- 服务器集群
- 大数据的技术基础
  - MapReduce 是分布式计算框架，GFS 是分布式文件系统，BigTable 是基于 GFS 的数据存储系统，这 3 大组件组成了 Google 的分布式计算模型

| 大数据系统体系 | 计算框架         | 文件系统 | 数据存储系统 |
| -------------- | ---------------- | -------- | ------------ |
| Hadoop 体系    | Hadoop MapReduce | HDFS     | HBase        |
| Google 体系    | MapReduce        | GFS      | BigTable     |

#### 18. Google 框架

- GFS
  - GFS 是一个大型的分布式文件系统，为 Google 大数据处理系统提供海量存储，并且与 MapReduce 和 BigTable 等技术结合得十分紧密，处于系统的底层
  - 优势
    - Client 和 Master Server 之间只有控制流，没有数据流，因此降低了 Master Server 的负载
    - 由于 Client 与 Chunk Server 之间直接传输数据流，并且文件被分成多个 Chunk 进行分布式存储，因此 Client 可以同时并行访问多个 Chunk Server，从而让系统的 I/O 并行度提高
  - 特点
    - 采用中心服务器模式
    - 不缓存数据
- MapReduce
  - MapReduce 是由 Google 开发的一个针对大规模群组中的海量数据处理的分布式编程模型
  - Map：把一个函数应用于集合中的所有成员，然后返回一个基于这个处理的结果集
  - Reduce：把两个或更多个 Map 通过多个线程、进程或者独立系统进行并行执行处理得到的结果集进行分类和归纳
  - 用户只需要提供自己的 Map 函数及 Reduce 函数就可以在集群上进行大规模的分布式数据处理
- BigTable
  - BigTable 是 Google 设计的分布式数据存储系统，是用来处理海量数据的一种非关系型数据库
  - BigTable 是一个稀疏的、分布式的、持久化存储的多维度排序的映射表
  - 面对的问题
    - 需要存储的数据种类繁多
    - 海量的服务请求
    - 商用数据库无法满足 Google 的需求
  - 设计目标
    - 广泛的适用性
    - 很强的可扩展性
    - 高可用性
    - 简单性

#### 19. Hadoop 框架

- Hadoop 是一个处理、存储和分析海量的分布式、非结构化数据的开源框架
- Hadoop 生态圈主要组件
  1. HDFS（GFS）：一个提供高可用的获取应用数据的**<u>分布式文件系统</u>**
  2. MapReduce：一个并行处理大数据集的**<u>编程模型</u>**
  3. HBase（BigTable）：一个可扩展的**<u>分布式数据库</u>**，支持大表的结构化数据存储。是一个建立在 HDFS 之上的，面向列的 [NoSQL](http://c.biancheng.net/nosql/) 数据库，用于快速读/写大量数据
  4. Hive：一个建立在 Hadoop 上的数据仓库基础构架
  5. Mahout：可扩展的机器学习和数据挖掘库
  6. Pig：一个支持并行计算的高级的数据流语言和执行框架，MapReduce 编程的复杂性的抽象
  7. Zookeeper：—个应用于分布式应用的高性能的协调服务
  8. Amban：一个基于 Web 的工具，用来供应、管理和监测 Hadoop 集群
  9. Sqoop：一个连接工具，用于在关系数据库、数据仓库和 Hadoop 之间转移数据
  10. Flume：提供了分布式、可靠、高效的服务，用于收集、汇总大数据，并将单台计算机的大量数据转移到 HDFS

### 6. HDFS

#### 20. 简介

- 分布式文件系统
  - 分布式文件系统是一种允许文件通过网络在多台主机上进行分享的文件系统，可让多台机器上的多用户分享文件和存储空间
- 特点
  - 在 HDFS 体系结构中有两类结点：一类是 NameNode，又叫“名称结点”；另一类是 DataNode，又叫“数据结点”。这两类结点分别承担 Master 和 Worker 具体任务的执行
  - HDFS 是一个主/从体系结构，从最终用户的角度来看，它就像传统的文件系统一样，可以通过目录路径对文件执行 CRUD（Create、Read、Update 和 Delete）操作
- 优劣
  - HDFS 主要针对“一次写入，多次读取”的应用场景，不适合实时交互性很强的应用场景，也不适合存储大量小文件

#### 21. 基本原理和设计理念

- 文件系统
  - 文件系统是操作系统提供的磁盘空间管理服务，该服务只需要用户指定文件的存储位置及文件读取路径，而不需要用户了解文件在磁盘上是如何存放的
- HDFS 的基本思想
  - 为了解决存储结点负载不均衡的问题，HDFS 首先把一个文件分割成多个块，然后再把这些文件块存储在不同服务器上
  - 为了保证文件的可靠性，HDFS 会把每个文件块进行多个备份，一般情况下是 3 个备份
  - 为了管理文件，HDFS 需要记录维护一些元数据，也就是关于文件数据信息的数据，如 HDFS 中存了哪些文件，文件被分成了哪些块，每个块被放在哪台服务器上等
  - HDFS 把这些元数据抽象为一个目录树，来记录这些复杂的对应关系。这些元数据由一个单独的模块进行管理，这个模块叫作名称结点（NameNode）。存放文件块的真实服务器叫作数据结点（DataNode）
- HDFS 的设计理念
  - 可构建在廉价机器上
  - 高容错性
  - 适合批处理
  - 适合存储大文件
- HDFS 的局限
  - 实时性差
  - 小文件问题
  - 文件修改问题

#### 22. 架构和实现机制

- 整体架构
  - NameNode
    - 文件的元数据
  - DataNode
    - 文件系统的工作结点
  - Client
    - 分别访问 NameNode 和 DataNode 以获取文件的元信息及内容

- 数据复制
  - NameNode 控制所有的数据块的复制决策
  - NameNode 周期性地从集群中的 DataNode 中收集心跳和数据块报告，收集到的数据块报告会包含相应 DataNode 上的所有数据块列表
  - 当一个硬盘故障时，HDFS 会检测到存储在该硬盘上的数据块的副本数量低于要求，然后主动创建需要的副本，以达到满副本数状态

#### 23. 读取和写入数据

- 特点
  - HDFS 的文件访问机制为流式访问机制，即通过 API 打开文件的某个数据块之后，可以顺序读取或者写入某个文件
- 读取流程
  - 客户端发起读取请求时，首先与 NameNode 进行连接
  - 连接建立完成后，客户端会请求读取某个文件的某一个数据块
  - 客户端接收到信息之后，与对应的 DataNode 连接，并开始进行数据传输
- 写入流程
  - 与 NameNode 建立连接，申请创建文件
  - 通过 FSDataOutputStream 写入数据
    - 将文件切分成多个分包（Packet）
    - 队列中的分包被打包成数据包，发往数据流管道中的第一个 DataNode，随后 DataNode 将数据包发送给下一个 DataNode
    - 接收到数据的 DataNode 要向发送者发送确认包（ACK Packet）
  - 确认返回成功，断开连接

#### 24. 操作方式

- 命令行

- Java API



### 7. HBase

#### 25. NoSQL 简介

- 易扩展、大数据量和高性能及灵活的数据模型
- 起因
  - 无法满足对海量数据的高效率存储和访问的需求
  - 无法满足对数据库的高可扩展性和高可用性的需求
  - 关系数据库无法存储和处理半结构化/非结构化数据
  - 关系数据库的事务特性对 Web 2.0 是不必要的
  - Web 2.0 无须进行复杂的 SQL 查询，特别是多表关联查询
- 特点
  - 灵活的可扩展性
  - 大数据量和高性能
  - 灵活的数据模型，可以处理半结构化/非结构化的大数据
- 问题
  - 成熟度
  - 支持：大多数 NoSQL 系统都是开源项目
  - 分析与商业智能
  - 管理
  - 专业

#### 26. NoSQL 类型

- 键值数据库
  - 简介
    - 键值数据库起源于 Amazon 开发的 Dynamo 系统，可以把它理解为一个分布式的 Hashmap
    - 在存在大量写操作的情况下，键值数据库可以比关系数据库有明显的性能优势
  - 分类
    - 内存键值数据库：把数据保存在内存中，Memcached 和 [Redis](http://c.biancheng.net/redis/)
    - 持久化键值数据库：把数据保存在磁盘中，BerkeleyDB、Voldmort 和 Riak
  - 局限
    - 键值数据库也有自身的局限性，主要是条件查询
    - 此外，键值数据库在发生故障时不支持回滚操作，所以无法支持事务
- 列式数据库
  - 列式数据库起源于 Google 的 BigTable，其数据模型可以看作是一个每行列数可变的数据表
  - 列式数据库更适合执行分析操作，如进行汇总或计数
- 文档数据库
  - 文档数据库是通过键来定位一个文档的，所以是键值数据库的一种衍生品
  - 文档数据库既可以根据键来构建索引，也可以基于文档内容来构建索引，这是文档数据库不同于键值数据库的主要方面
- 图形数据库
  - 图形数据库是 NoSQL 数据库类型中最复杂的一个
  - 适用于高度相互关联的数据，可以高效地处理实体间的关系
  - 典型的图形数据库有 Neo4J、OrientDB、InfoGrid、Infinite Graph 和 GraphDB 等

#### 27. HBase 简介

- 简介
  - 是基于 Apache Hadoop 的面向列的 [NoSQL](http://c.biancheng.net/nosql/) 数据库，是 Google 的 BigTable 的开源实现
  - HBase 和传统关系数据库不同，它采用了 BigTable 的数据模型增强的稀疏排序映射表（Key/Value），其中，键由<u>**行关键字、列关键字和时间戳**</u>构成
- 特点
  - Hadoop 是一个高容错、高延时的分布式文件系统和高并发的批处理系统，不适用于提供实时计算
  - 而 HBase 是可以提供实时计算的分布式数据库，数据被保存在 HDFS (分布式文件系统）上，由 HDFS 保证其高容错性
  - HBase 可以直接使用本地文件系统，也可以使用 Hadoop 的 HDFS
  - HBase 把经常需要一起处理的列构成列族一起存放，从而避免了需要对这些列进行重构的操作

#### 28. HBase 列式数据模型

- 概述
  - HBase 是一个稀疏、多维度、有序的映射表
  - 在同一个表模式下，每行所包含的列族是相同的，也就是说，列族的个数与名称都是相同的，但是每一行中的每个列族中列的个数可以不同
  - HBase 执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，原有的版本仍然保留
- 特点
  - 稀疏
    - 尽管表中的每一行会拥有相同的列族，但是可能具有截然不同的列。正因为如此，对于整个映射表的每行数据而言，有些列的值就是空的，所以 HBase 的表是稀疏的
  - 多维度
    - 行键、列族、列限定符和时间戳
  - 有序
    - 表的行是按照行键顺序来进行存储的
- 数基本概念
  - 表（Table）
  - 行（Row）
    - 设计行键的一个重要原则就是相关的行键要存储在接近的位置，例如，设计记录网站的表时，行键需要将域名反转（例如，org.apache.www、org.apache.mail、org.apache.jira），这样的设计能使与 apache 相关的域名在表中存储的位置非常接近
  - 列（Column）
    - 列族（Column Family)
    - 列限定符（Column Qualifier）
    - 列族必须在表建立的时候声明，列随时可以新建
  - 单元（Cell）
    - 行键、列族和列限定符一起标识一个单元
  - 时间戳（Timestamp）

- 概念视图
  - 要定位单元中的数据可以采用“三维坐标”来进行，也就是 [行键，列族:列限定符，时间戳]
- 物理视图
  - 在物理存储层面来看，HBase 采用了基于列的存储方式
  - 属于同一个列族的数据保存在一起，同时，和每个列族一起存放的还包括行键和时间戳

#### 29. HBase Shell

- HBase Shell 提供了大多数的 HBase 命令，通过 HBase Shell，用户可以方便地创建、删除及修改表，还可以向表中添加数据，列出表中的相关信息等

#### 30. HBase 主要运行机制

- 物理存储
  - Region
    - HBase 表中的所有行都是按照行键的字典序排列的，当一张表的行太多的时候，HBase 就会根据行键的值对表中的行进行分区，每个行区间构成一个“分区（Region）”，包含了位于某个值域区间内的所有数据
    - Region 是 HBase 中数据分发和负载均衡的最小单元，默认大小是 100MB 到 200MB
    - 不同的 Region 可以分布在不同的 Region Server 上，但一个 Region 不会拆分到多个 Region Server 上。每个 Region Server 负责管理一个 Region 集合
    - Region 是 HBase 在 Region Server 上数据分发的最小单元，但并不是存储的最小单元。事实上，每个 Region  由一个或者多个 Store 组成，每个 Store 保存一个列族的数据
- 逻辑架构
  - 在分布式的生产环境中，HBase 需要运行在 HDFS 之上，以 HDFS 作为其基础的存储设施
  - HBase 的集群主要由 Master、Region Server 和 Zookeeper 组成
  -  Master
    - 主要负责表和 Region 的管理工作
  - Region Server
    - Client 直接与 Region Server 连接，并经过通信获取 HBase 中的数据
    - HBase 釆用 HDFS 作为底层存储文件系统，Region Server 需要向 HDFS 写入数据，并利用 HDFS 提供可靠稳定的数据存储，所以 Region Server 并不需要提供数据复制和维护数据副本的功能
  - Zookeeper
    - 保证了至少有一个 HBase Master 处于运行状态
    - 同时负责管理 Region Server 状态，每个 Region Server 都向 Zookeeper 注册，由 Zookeeper 实时监控每个 Region Server 的状态，并通知给 Master

#### 31. HBase Java API

- HBase 主要包括 5 大类操作
  - HBase 的配置
  - HBase 表的管理
  - 列族的管理
  - 列的管理
  - 数据操作

#### 32. HBase Java 编程实例

- 在本实例中，首先创建一个学生成绩表 scores，用来存储学生各门课程的考试成绩，然后向 scores 添加数据



### 8. MapReduce

#### 33. Hadoop MapReduce

- 批处理模式
  - 由于批处理在应对大量持久数据方面的表现极为出色，因此经常被用于对历史数据进行分析
  - 为了提高处理效率，对大规模数据集进行批处理需要借助分布式并行程序
  - Google 最先实现了分布式并行处理模式 MapReduce，并于 2004 年以论文的方式对外公布了其工作原理，Hadoop MapReduce 是它的开源实现
- 简介
  - 映射（Map)
    - 对集合中的每个元素进行同一个操作
  - 化简（Reduce)
    - 遍历集合中的元素来返回一个综合的结果
- 基本思想
  - 大数据处理思想：分而治之
  - 构建抽象模型：Map 函数和 Reduce 函数
    - MapReduce 定义了 Map 和 Reduce 两个抽象的编程接口，为程序员提供了一个清晰的操作接口抽象描述，由用户去编程实现
  - 上升到架构：并行自动化并隐藏底层细节
    - 任务调度
    - 数据/程序互定位
    - 出错处理
    - 分布式数据存储与文件管理
    - Combiner 和 Partitioner
- Map 函数和 Reduce 函数

| 函数   | 输入          | 输出          | 注解                                                         |
| ------ | ------------- | ------------- | ------------------------------------------------------------ |
| Map    | Map<k1,V1>    | List(<k2,V2>) | 将输入数据集分解成一批<key,value>对，然后进行处理；每一个<key,value>输入，Map 会输出一批<K2,V2> |
| Reduce | <k2,List(V2)> | <K3,V3>       | MapReduce 框架会把 Map 的输出，按 key 归类为 <K2,List(V2)>。List(V2) 是一批属于同一个 K2 的 value |

#### 34. 架构

- 流程
  - 首先把存储在 HDFS 中的输入数据集切分为若干个独立的数据块，由多个 Map 任务（Task）以完全并行的方式处理这些数据块
  - MapReduce 框架会对 Map 任务的输出先进行排序，然后把结果作为输入传送给 Reduce 任务
- 架构
  - JobClient
  - JobTracker
  - TaskTracker
  - Task
- 补充
  - Hadoop MapReduce 框架和 HDFS 是运行在一组相同的结点上的
  - 这种配置允许框架在那些已经存好数据的结点上高效地调度任务

#### 35. 工作流程

- 实际处理过程
  - Input
  - Map
  - Sort
  - Combine
  - Partition
  - Reduce
  - Output
- 补充
  - 在 MapReduce 的整个处理过程中，不同的任务之间不会进行任何通信，用户不能够显式地从一个结点向另一个结点发送消息，所有的信息交换都是通过 MapReduce 框架实现的
  - 如分布式存储、分布式通信、任务调度、容错处理、负载均衡、数据可靠等，这些问题都由 Hadoop MapReduce 框架负责处理，应用开发者只需要负责完成 Map 函数与 Reduce 函数的实现

#### 36. 实例分析

- 单词计数是最简单也是最能体现 MapReduce 思想的程序之一，可以称为 MapReduce 版“Hello World”

#### 37. 工作机制

- 作业执行流程
  1. 提交作业
     - 作业提交之后，就会进入自动化执行。在这个过程中，用户只能监控程序的执行情况和强制中断作业，但是不能对作业的执行过程进行任何干预
  2. 初始化作业
     - 跟踪任务的状态和进程
  3. 分配任务
     - 对于 Map 任务，JobTracker 通常会选取一个距离其输入分片最近的 TaskTracker，对于 Reduce 任务，JobTracker 则无法考虑数据的本地化
  4. 执行任务
     - TaskTracker 启动一个新的 JVM 来运行每个任务（包括 Map 任务和 Reduce 任务），这样，JobClient 的 MapReduce 就不会影响 TaskTracker 守护进程
  5. 进程和状态的更新
     - 一个作业和它的每个任务都有一个状态信息，这些消息通过一定的时间间隔由 ChildJVM 向 TaskTracker 汇聚，然后再向 JobTracker 汇聚
  6. 完成作业
- Shuffle 过程
  - 指从 Map 的输出开始，包括系统执行排序，以及传送 Map 输出到 Reduce 作为输入的过程
  - Map 端的 Shuffle 阶段
    - Map 函数开始产生输出时，并不是简单地把数据写到磁盘中，因为频繁的磁盘操作会导致性能严重下降。它的处理过程是把数据首先写到内存中的一个缓冲区， 并做一些预排序，以提升效率
    - 在写磁盘前，线程首先根据数据最终要传递到的 Reduce 任务把数据划分成相应的分区（Partition）。在每个分区中，后台线程按 Key 进行排序，如果有一个 Combiner，便会在排序后 的输出上运行
    - 在 Map 任务完成前，多个溢出写文件被合并成一个索引文件和数据文件（多路归并排序）（Sort 阶段)
  - Reduce 端的 Shuffle 阶段
    - 将 Map 端复制过来的数据先放入内存缓冲区中， 执行类似于 Map 生成数据的流程（Spill）
    - Reduce 的输入文件已定，整个 Shuffle 阶段就结束了，然后就是 Reduce 执行
- Hadoop MapReduce 的主要特点
  - 向“外”横向扩展，而非向“上”纵向扩展
  - 失效被认为是常态
  - 把处理向数据迁移
  - 顺序处理数据，避免随机访问数据
  - 为应用开发者隐藏系统层细节
  - 平滑无缝的可扩展性

#### 38. 编程实例

- 任务准备
- 编写程序
- 运行代码



## 第四部分 Spark

#### 39. 简介

- Hadoop MapRedcue 的缺点
  - 表达能力有限
  - 磁盘 I/O 开销大
  - 计算延迟高

- Spark 的优势
  - 内存计算
  - 模式多样化
  - 更加通用
  - 任务调度机制更优越
- Spark 的劣势
  - 因为 Spark 是基于内存进行数据处理的，所以不适合于数据量特别大、对实时性要求不高的场合
  - Hadoop 可以使用廉价的通用服务器来搭建集群，而 Spark 对硬件要求比较高，特别是对内存和 CPU 有更高的要求

- 大数据处理场景
  - 复杂的批量处理
    - MapReduce
  - 基于历史数据的交互式查询
    - 用 Impala 进行交互式查询
  - 基于实时数据流的数据处理
    - 用 Storm 分布式处理框架处理实时流式数据
- Spark 适用场景
  - 需要多次操作特定数据集的应用场合
  - 数据量不是特别大，但是要求实时统计分析
  - Spark 不适用于那种异步细粒度更新状态的应用

#### 40. RDD

- 基本概念
  - 简介
    - 弹性分布式数据集 (Resiliennt Distributed Datasets)
    - 可以将 RDD 理解为一个分布式对象集合，本质上是一个只读的分区记录集合
    - 一个 RDD 的不同分区可以保存到集群中的不同结点上，从而可以在集群中的不同结点上进行并行计算
    - 实质上是一种更为通用的迭代并行计算框架，用户可以显示控制计算的中间结果，然后将其自由运用于之后的计算
  - 属性
    - 只读
    - 分布式
    - 弹性
    - 基于内存

- 基本操作

  - 构建操作

    1. 从内存里直接读取数据

       - ```scala
         val rdd01 = sc.makeRDD(List(1,2,3,4,5,6))
         ```

    2. 或者文件系统里读取数据

       - ```scala
         val rdd:RDD[String] == sc.textFile("file:///D:/spark-3.0.0-bin-hadoop3.2/README.md",1)
         ```

  - 转换操作（Transformation）

    - 一个 RDD 产生一个新的 RDD
    - 转换出来的 RDD 是惰性求值的，只有在行动操作中用到这些 RDD 时才会被计算

  - 行动操作（Action）

    - 行动操作用于执行计算并按指定的方式输出结果
    - 行动操作接受 RDD，但是返回非 RDD，即输出一个值或者结果

- 血缘关系

  - 描述了一个 RDD 是如何从父 RDD 计算得来的

- 依赖类型

  - 窄依赖
    - 子 RDD 的每个分区依赖于常数个父分区（即与数据规模无关)
    - 输入输出一对一的算子，且结果 RDD 的分区结构不变，如 map、flatMap
    - 输入输出一对一的算子，但结果 RDD 的分区结构发生了变化，如 union
    - 从输入中选择部分元素的算子，如 filter、distinct、subtract、sample
  - 宽依赖
    - 子 RDD 的每个分区依赖于所有父 RDD 分区
    - 对单个 RDD 基于 Key 进行重组和 reduce，如 groupByKey、reduceByKey
    - 对两个 RDD 基于 Key 进行 join 和重组，如 join

- 阶段划分

  - 由于宽依赖会带来“洗牌”，所以不同的 Stage 是不能并行计算的，后面 Stage 的 RDD 的计算需要等待前面 Stage 的 RDD 的所有分区全部计算完毕以后才能进行
  - 把一个 DAG 图划分成多个 Stage 以后，每个 Stage 都代表了一组由关联的、相互之间没有宽依赖关系的任务组成的任务集合。在运行的时候，Spark 会把每个任务集合提交给任务调度器进行处理

- RDD 缓存

  - 如果简单地对 RDD 调用行动操作，Spark 每次都会重算 RDD 及它的依赖，这样就会带来太大的消耗
  - 为了避免多次计算同一个 RDD，可以让 Spark 对数据进行持久化
  - Spark 可以使用 persist 和 cache 方法将任意 RDD 缓存到内存、磁盘文件系统中
    - cache 是 persist 的特例，将该 RDD 缓存到内存中
    - persist 可以让用户根据需求指定一个持久化级别，来决定缓存到内存或者磁盘中
  - 在不使用 cached RDD 的时候，及时使用 unpersist 方法来释放它

#### 41. 总体架构和运行流程

- 总体架构
  - 任务控制结点（Driver）
    - Driver 是运行 Spark Applicaion 的 main() 函数，它会创建 SparkContext
    - SparkContext 负责和 Cluster Manager 通信，进行资源申请、任务分配和监控等
  - 集群资源管理器（Cluster Manager）
    - 负责申请和管理在 Worker Node 上运行应用所需的资源
  - 工作结点（Worker Node）
  - 执行进程（Executor）
    - Executor 是 Application 运行在 Worker Node 上的一个进程，负责运行多个 Task（任务）
    - 与 MapReduce 计算框架相比，Spark 采用的 Executor 具有两大优势
      - Executor 利用多线程来执行具体任务
      - Executor 中有一个 BlockManager 存储模块，会将内存和磁盘共同作为存储设备
- 运行流程
  - 基本流程
    - 启动 SparkContext
    - Cluster Manager 为 Executor 分配资源并启动 Executor 进程
    - DAG Scheduler 构建 DAG 图，并把每个 Stage 的 TaskSet（任务集）发送给 Task Scheduler (任务调度器），Task Scheduler 将 Task 发放给 Executor
    - Task 在 Executor 上运行，把执行结果反馈给 Task Scheduler，然后再反馈给 DAG Scheduler
  - 特点
    - 每个 Application 拥有专属的 Executor 进程，该进程在 Application 运行期间一直驻留，并以多线程方式运行任务
    - Spark 与 Cluster Manager 无关，只要能够获取 Executor 进程，并能保持相互通信即可
    - 在 Spark Application 运行过程中，SparkContext 和 Executor 之间有大量的信息交换
    - Task 采用了数据本地性和推测执行的优化机制
    - Executor 上的 BlockManager（存储模块），可以把内存和磁盘共同作为存储设备

#### 42. Spark 生态圈

- Spark Core 内核
  - 提供了有向无环图（DAG）的分布式并行计算框架，并提供 cache 机制来支持多次迭代计算或者数据共享
  - 在 Spark 中引入了 RDD 的抽象
  - 移动计算而非移动数据
  - 使用多线程池模型来减少 Task 启动开销
  - 采用容错的、高可伸缩性的 Akka 作为通信框架
- Spark Streaming
  - Spark Streaming 是一个对实时数据流进行高通量、容错处理的流式处理系统
- Spark SQL
  - Spark SQL 允许开发人员直接处理 RDD，以及查询存储在 Hive、HBase 上的外部数据
- Spark MLlib
  - 实现了一些常见的机器学习算法和实用程序
- Spark GraphX
  - 用于图并行计算的 API

#### 43. 开发实例

- 通过 Spark Shell
- 通过 Java 应用程序

#### 44. Spark Streaming 简介

- Spark Streaming 是 Spark 核心 API 的一个扩展，可以实现高吞吐量的、具备容错机制的实时流数据的处理
- 处理机制
  - 接收实时的输入数据流，并根据一定的时间间隔（如 1 秒）拆分成一批批的数据，然后通过 Spark Engine 处理这些批数据，最终得到处理后的一批批结果数据
- DStream
  - Spark Streaming 支持一个高层的抽象，叫作离散流（Discretized Stream）或者 DStream，它代表连续的数据流
  - 一批数据在 Spark 内核中对应一个 RDD 实例
  - 因此，对应流数据的 DStream 可以看成是一组 RDD，即 RDD 的一个序列

#### 45. 系统架构

- 传统流处理系统架构
  - 