---
layout: post
title:  【C 语言中文网】大数据 - 笔记
date:   2020-06-08
categories: 大数据
---

## 第一部分 概览

### 1. 意义

#### 1. 简介

- 大数据是指无法在有限时间内用常规软件工具对其进行获取、存储、管理和处理的数据集合
- Volume、Velocity、Variety 和 Value 四个特征，即体量巨大、速度快、类型繁多和价值密度低

#### 2. 时代

- 从宏观上看，由于大数据革命的系统性影响和深远意义，主要大国快速做出战略响应，将大数据置于非常核心的位置，推出国家级创新战略计划
- 从微观上看，大数据重塑了企业的发展战略和转型方向

#### 3. 产生和作用

- 产生
  - 运营式系统阶段，被动产生
  - 用户原创内容阶段，主动产生
  - 感知式系统阶段，自动产生
- 作用
  - 对大数据的处理分析正成为新一代信息技术融合应用的<u>结点</u>
  - 大数据是信息产业持续高速增长的新<u>引擎</u>
  - 大数据利用将成为提高核心竞争力的关键因素
  - 大数据时代，科学研究的方法手段将发生重大改变

#### 4. 重大变化

1. 研究范式
2. 数据重要性
3. 方法论
4. 数据分析
5. 计算智能
6. 管理目标
7. 决策方式
8. 产业竞合关系
9. 对数据复杂性的认识
10. 数据处理模式



### 2. 基本方法

#### 5. 基本流程

- 数据抽取与集成
  - 基于物化或 ETL 方法的引擎
  - 基于联邦数据库或中间件方法的引擎
  - 基于数据流方法的引擎
  - 以及基于搜索引擎的方法
- 数据分析
  - 数据量大并不一定意味着数据价值的增加，相反这往往意味着数据噪音的增多
  - 大数据时代的算法需要进行调整
  - 数据结果的衡量标准
- 数据解释
  - 引入可视化技术
  - 让用户能够在一定程度上了解和参与具体的分析过程

#### 6. 关键技术

- 采集《[7. 大数据采集技术概述](http://c.biancheng.net/view/3526.html)》
  - 来源
    - 运营数据库
    - 社交网络
    - 感知设备
- 预处理《[11. 大数据预处理架构和方法](http://c.biancheng.net/view/3544.html)》
  - 步骤
    - 数据清理
    - 数据集成和变换
    - 数据规约
- 存储及管理
  - 用存储器把采集到的数据存储起来，建立相应的数据库，并进行管理和调用
  - 分布式存储技术
    - 分布式文件系统：非结构化数据，GFS《[Hadoop HDFS分布式文件系统](http://c.biancheng.net/view/3569.html)》
    - NoSQL 数据库系统：半结构化，BigTable，Dynamo，MongoDB《[NoSQL非关系型数据库](http://c.biancheng.net/view/3581.html)》
    - 数据仓库系统：结构化数据，Hive
- 处理
  - 批处理模式
    - MapReduce《[Hadoop MapReduce概述](http://c.biancheng.net/view/3604.html)》
    - 将问题分而治之，把待处理的数据分成多个模块分别交给多个 Map 任务去并发处理
    - 把计算推到数据而不是把数据推到计算，从而有效地避免数据传输过程中产生的大量通信开销
  - 流处理模式
    - Spark《[Spark简介](http://c.biancheng.net/view/3642.html)》《[Spark Streaming简介](http://c.biancheng.net/view/3658.html)》
- 分析及挖掘《[数据挖掘分析](http://c.biancheng.net/view/3675.html)》
  - 常用算法
    - 分类
    - 回归分析
    - 聚类
    - 关联规则
- 大数据展示
  - 数据可视化



## 第二部分 采集与预处理

### 3. 采集

#### 7. 简介

- 不但数据源的种类多，数据的类型繁杂，数据量大，并且产生的速度快，传统的数据采集方法完全无法胜任
- 分类
  - 数据类型
    - 业务数据
    - 行业数据
    - 内容数据【新】
    - 线上行为数据【新】
    - 线下行为数据【新】
  - 数据来源
    - 企业系统
    - 机器系统【新】
    - 互联网系统【新】
    - 社交系统【新】
- 采集方法
  - 数据库采集
  - 系统日志采集《[8. 系统日志采集方法](http://c.biancheng.net/view/3527.html)》
  - 网络数据采集《[9. 网络数据采集方法](http://c.biancheng.net/view/3530.html)》
  - 感知设备数据采集

#### 8. 日志系统采集

- 目前使用最广泛的、用于系统日志采集的海量数据采集工具有 Hadoop 的 Chukwa、Apache 的 Flume、Facebook 的 Scribe 和 LinkedIn 的 Kafka 等
- Flume
  - Flume 的核心是把数据从数据源（Source）收集过来，再将收集到的数据送到指定的目的地（Sink）
  - Flume 的用法很简单，主要是编写一个用户配置文件。在配置文件当中描述 Source、Channel 与 Sink 的具体实现，而后运行一个 Agent 实例

#### 9. 网络数据采集

- 网络数据采集是指通过网络爬虫或网站公开 API 等方式从网站上获取数据信息
- 网络爬虫工具分类
  - 分布式网络爬虫工具，如 Nutch
  - [Java](http://c.biancheng.net/java/) 网络爬虫工具，如 Crawler4j、WebMagic、WebCollector
  - 非 Java 网络爬虫工具，如 Scrapy(基于 [Python](http://c.biancheng.net/python/) 语言开发)
- 网页间关系模型
  - 彼此关联、庞大复杂的有向图
- 网页分类
  - 已下载未过期网页、已下载已过期网页
  - 待下载网页
  - 可知网页
  - 不可知网页
- 抓取策略
  - 通用网络爬虫（全网爬虫）
    - 深度优先策略
    - 广度优先策略
  - 聚焦网络爬虫（主题网络爬虫）
    - 基于内容评价的爬行策略：Shark Search 算法
    - 基于链接结构评价的爬行策略：PageRank 算法
    - 基于增强学习的爬行策略
    - 基于语境图的爬行策略
  - 增量式网络爬虫
    - 对已下载网页采取增量式更新并且只爬行新产生的或者已经发生变化网页的爬虫
  - 深层网络爬虫
    - 深层网页是那些大部分内容不能通过静态链接获取的，隐藏在搜索表单后的，只有用户提交一些关键词才能获得的网页

#### 10. Scrapy 网络爬虫

- Scrapy 是一个为了爬取网站数据、提取结构性数据而编写的应用框架
- Scrapy 的整体架构由 Scrapy 引擎（ScrapyEngine）、调度器（Scheduler）、下载器（Downloader）、爬虫（Spiders）和数据项管道（itemPipeline）5 个组件组成



### 4. 预处理

#### 11. 简介

- 数据预处理主要包括数据清洗（Data Cleaning）、数据集成（Data Integration）、数据转换（Data Transformation）和数据消减（Data Reduction）
- 结构化数据
  - 传统 ETL 工具
  - 传统的关系型数据库
  - 关系型数据库在处理事务、及时响应、保证数据的一致性方面有天然的优势
- 半结构化/非结构化数据
  - 分布式并行处理框架
  - 半结构化：分布式 [NoSQL](http://c.biancheng.net/nosql/) 数据库中，如 [HBase](http://c.biancheng.net/hbase/)
  - 非结构化：新型的分布式存储中，如 Hadoop 的 HDFS
  - 分布式存储在系统的横向扩展性、存储成本、文件读取速度方面有着显著的优势
- 数据质量问题

#### 12. 数据清洗

- 现实世界的数据常常是不完全的、有噪声的、不一致的
- 主要方法
  1. 遗漏数据处理
  2. 噪声数据处理
     1. Bin 方法
     2. 聚类分析方法
     3. 人机结合检查方法
     4. 回归方法
  3. 不一致数据处理

#### 13. 数据集成

- 将来自多个数据源的数据，如数据库、数据立方、普通文件等，结合在一起并形成一个统一数据集合，以便为数据处理工作的顺利完成提供完整的数据基础
- 问题
  - 模式集成问题
  - 冗余问题
  - 数据值冲突检测与消除问题：单位，编码不一致

#### 14. 数据转换

- 将数据进行转换或归并，从而构成一个适合数据处理的描述形式
- 主要方法
  1. 平滑处理：即噪声数据处理
  2. 合计处理
  3. 数据泛化处理
  4. 规格化处理
     - 将一个属性取值范围投射到一个特定范围之内
  5. 属性构造处理
     - 根据已有属性集构造新的属性

#### 15. 数据消减

- 从原有巨大数据集中获得一个精简的数据集，并使这一精简数据集保持原有数据集的完整性
- 主要方法
  1. 数据立方合计
  2. 维数消减
     - 只保留有用的属性
  3. 数据压缩
     - 离散小波转换（Discrete Wavelet Transforms）
     - 主要素分析（Principal Components Analysis）
  4. 数据块消减
     - 回归与线性对数模型
     - 直方图
     - 聚类
     - 采样
  5. 离散化与概念层次生成

#### 16. 离散化和数值概念层次树

- 离散化技术方法可以通过将属性（连续取值）域值范围分为若干区间，来帮助消减一个连续（取值）属性的取值个数
- 数值概念层次树
  - Bin 方法
  - 直方图方法
  - 聚类分析方法
  - 基于熵的方法
  - 自然划分分段方法
- 类别概念层次树
  - 类别数据是一种离散数据。类别属性可取有限个不同的值且这些值之间无大小和顺序，如国家、工作、商品类别等
  - 一个重要线索就是，高层次概念通常包含了若干低层次概念。定义属性的高层次概念通常比低层次概念包含少一些的不同值



## 第三部分 Hadoop 框架

### 5. 大数据处理技术

#### 17. 处理技术

- 分布式计算
- 服务器集群
- 大数据的技术基础
  - MapReduce 是分布式计算框架，GFS 是分布式文件系统，BigTable 是基于 GFS 的数据存储系统，这 3 大组件组成了 Google 的分布式计算模型

| 大数据系统体系 | 计算框架         | 文件系统 | 数据存储系统 |
| -------------- | ---------------- | -------- | ------------ |
| Hadoop 体系    | Hadoop MapReduce | HDFS     | HBase        |
| Google 体系    | MapReduce        | GFS      | BigTable     |

#### 18. Google 框架

- GFS
  - GFS 是一个大型的分布式文件系统，为 Google 大数据处理系统提供海量存储，并且与 MapReduce 和 BigTable 等技术结合得十分紧密，处于系统的底层
  - 优势
    - Client 和 Master Server 之间只有控制流，没有数据流，因此降低了 Master Server 的负载
    - 由于 Client 与 Chunk Server 之间直接传输数据流，并且文件被分成多个 Chunk 进行分布式存储，因此 Client 可以同时并行访问多个 Chunk Server，从而让系统的 I/O 并行度提高
  - 特点
    - 采用中心服务器模式
    - 不缓存数据
- MapReduce
  - MapReduce 是由 Google 开发的一个针对大规模群组中的海量数据处理的分布式编程模型
  - Map：把一个函数应用于集合中的所有成员，然后返回一个基于这个处理的结果集
  - Reduce：把两个或更多个 Map 通过多个线程、进程或者独立系统进行并行执行处理得到的结果集进行分类和归纳
  - 用户只需要提供自己的 Map 函数及 Reduce 函数就可以在集群上进行大规模的分布式数据处理
- BigTable
  - BigTable 是 Google 设计的分布式数据存储系统，是用来处理海量数据的一种非关系型数据库
  - BigTable 是一个稀疏的、分布式的、持久化存储的多维度排序的映射表
  - 面对的问题
    - 需要存储的数据种类繁多
    - 海量的服务请求
    - 商用数据库无法满足 Google 的需求
  - 设计目标
    - 广泛的适用性
    - 很强的可扩展性
    - 高可用性
    - 简单性

#### 19. Hadoop 框架

- Hadoop 是一个处理、存储和分析海量的分布式、非结构化数据的开源框架
- Hadoop 生态圈主要组件
  1. HDFS（GFS）：一个提供高可用的获取应用数据的**<u>分布式文件系统</u>**
  2. MapReduce：一个并行处理大数据集的**<u>编程模型</u>**
  3. HBase（BigTable）：一个可扩展的**<u>分布式数据库</u>**，支持大表的结构化数据存储。是一个建立在 HDFS 之上的，面向列的 [NoSQL](http://c.biancheng.net/nosql/) 数据库，用于快速读/写大量数据
  4. Hive：一个建立在 Hadoop 上的数据仓库基础构架
  5. Mahout：可扩展的机器学习和数据挖掘库
  6. Pig：一个支持并行计算的高级的数据流语言和执行框架，MapReduce 编程的复杂性的抽象
  7. Zookeeper：—个应用于分布式应用的高性能的协调服务
  8. Amban：一个基于 Web 的工具，用来供应、管理和监测 Hadoop 集群
  9. Sqoop：一个连接工具，用于在关系数据库、数据仓库和 Hadoop 之间转移数据
  10. Flume：提供了分布式、可靠、高效的服务，用于收集、汇总大数据，并将单台计算机的大量数据转移到 HDFS

### 6. HDFS

#### 20. 简介

- 分布式文件系统
  - 分布式文件系统是一种允许文件通过网络在多台主机上进行分享的文件系统，可让多台机器上的多用户分享文件和存储空间
- 特点
  - 在 HDFS 体系结构中有两类结点：一类是 NameNode，又叫“名称结点”；另一类是 DataNode，又叫“数据结点”。这两类结点分别承担 Master 和 Worker 具体任务的执行
  - HDFS 是一个主/从体系结构，从最终用户的角度来看，它就像传统的文件系统一样，可以通过目录路径对文件执行 CRUD（Create、Read、Update 和 Delete）操作
- 优劣
  - HDFS 主要针对“一次写入，多次读取”的应用场景，不适合实时交互性很强的应用场景，也不适合存储大量小文件

#### 21. 基本原理和设计理念

- 文件系统
  - 文件系统是操作系统提供的磁盘空间管理服务，该服务只需要用户指定文件的存储位置及文件读取路径，而不需要用户了解文件在磁盘上是如何存放的
- HDFS 的基本思想
  - 为了解决存储结点负载不均衡的问题，HDFS 首先把一个文件分割成多个块，然后再把这些文件块存储在不同服务器上
  - 为了保证文件的可靠性，HDFS 会把每个文件块进行多个备份，一般情况下是 3 个备份
  - 为了管理文件，HDFS 需要记录维护一些元数据，也就是关于文件数据信息的数据，如 HDFS 中存了哪些文件，文件被分成了哪些块，每个块被放在哪台服务器上等
  - HDFS 把这些元数据抽象为一个目录树，来记录这些复杂的对应关系。这些元数据由一个单独的模块进行管理，这个模块叫作名称结点（NameNode）。存放文件块的真实服务器叫作数据结点（DataNode）
- HDFS 的设计理念
  - 可构建在廉价机器上
  - 高容错性
  - 适合批处理
  - 适合存储大文件
- HDFS 的局限
  - 实时性差
  - 小文件问题
  - 文件修改问题

#### 22. 架构和实现机制

- 整体架构
  - NameNode
    - 文件的元数据
  - DataNode
    - 文件系统的工作结点
  - Client
    - 分别访问 NameNode 和 DataNode 以获取文件的元信息及内容

- 数据复制
  - NameNode 控制所有的数据块的复制决策
  - NameNode 周期性地从集群中的 DataNode 中收集心跳和数据块报告，收集到的数据块报告会包含相应 DataNode 上的所有数据块列表
  - 当一个硬盘故障时，HDFS 会检测到存储在该硬盘上的数据块的副本数量低于要求，然后主动创建需要的副本，以达到满副本数状态

#### 23. 读取和写入数据

- 特点
  - HDFS 的文件访问机制为流式访问机制，即通过 API 打开文件的某个数据块之后，可以顺序读取或者写入某个文件
- 读取流程
  - 客户端发起读取请求时，首先与 NameNode 进行连接
  - 连接建立完成后，客户端会请求读取某个文件的某一个数据块
  - 客户端接收到信息之后，与对应的 DataNode 连接，并开始进行数据传输
- 写入流程
  - 与 NameNode 建立连接，申请创建文件
  - 通过 FSDataOutputStream 写入数据
    - 将文件切分成多个分包（Packet）
    - 队列中的分包被打包成数据包，发往数据流管道中的第一个 DataNode，随后 DataNode 将数据包发送给下一个 DataNode
    - 接收到数据的 DataNode 要向发送者发送确认包（ACK Packet）
  - 确认返回成功，断开连接

#### 24. 操作方式

- 命令行

- Java API



### 7. HBase

#### 25. NoSQL 简介

- 易扩展、大数据量和高性能及灵活的数据模型
- 起因
  - 无法满足对海量数据的高效率存储和访问的需求
  - 无法满足对数据库的高可扩展性和高可用性的需求
  - 关系数据库无法存储和处理半结构化/非结构化数据
  - 关系数据库的事务特性对 Web 2.0 是不必要的
  - Web 2.0 无须进行复杂的 SQL 查询，特别是多表关联查询
- 特点
  - 灵活的可扩展性
  - 大数据量和高性能
  - 灵活的数据模型，可以处理半结构化/非结构化的大数据
- 问题
  - 成熟度
  - 支持：大多数 NoSQL 系统都是开源项目
  - 分析与商业智能
  - 管理
  - 专业

#### 26. NoSQL 类型

- 键值数据库
  - 简介
    - 键值数据库起源于 Amazon 开发的 Dynamo 系统，可以把它理解为一个分布式的 Hashmap
    - 在存在大量写操作的情况下，键值数据库可以比关系数据库有明显的性能优势
  - 分类
    - 内存键值数据库：把数据保存在内存中，Memcached 和 [Redis](http://c.biancheng.net/redis/)
    - 持久化键值数据库：把数据保存在磁盘中，BerkeleyDB、Voldmort 和 Riak
  - 局限
    - 键值数据库也有自身的局限性，主要是条件查询
    - 此外，键值数据库在发生故障时不支持回滚操作，所以无法支持事务
- 列式数据库
  - 列式数据库起源于 Google 的 BigTable，其数据模型可以看作是一个每行列数可变的数据表
  - 列式数据库更适合执行分析操作，如进行汇总或计数
- 文档数据库
  - 文档数据库是通过键来定位一个文档的，所以是键值数据库的一种衍生品
  - 文档数据库既可以根据键来构建索引，也可以基于文档内容来构建索引，这是文档数据库不同于键值数据库的主要方面
- 图形数据库
  - 图形数据库是 NoSQL 数据库类型中最复杂的一个
  - 适用于高度相互关联的数据，可以高效地处理实体间的关系
  - 典型的图形数据库有 Neo4J、OrientDB、InfoGrid、Infinite Graph 和 GraphDB 等

#### 27. HBase 简介

- 简介
  - 是基于 Apache Hadoop 的面向列的 [NoSQL](http://c.biancheng.net/nosql/) 数据库，是 Google 的 BigTable 的开源实现
  - HBase 和传统关系数据库不同，它采用了 BigTable 的数据模型增强的稀疏排序映射表（Key/Value），其中，键由<u>**行关键字、列关键字和时间戳**</u>构成
- 特点
  - Hadoop 是一个高容错、高延时的分布式文件系统和高并发的批处理系统，不适用于提供实时计算
  - 而 HBase 是可以提供实时计算的分布式数据库，数据被保存在 HDFS (分布式文件系统）上，由 HDFS 保证其高容错性
  - HBase 可以直接使用本地文件系统，也可以使用 Hadoop 的 HDFS
  - HBase 把经常需要一起处理的列构成列族一起存放，从而避免了需要对这些列进行重构的操作

#### 28. HBase 列式数据模型

- 概述
  - HBase 是一个稀疏、多维度、有序的映射表
  - 在同一个表模式下，每行所包含的列族是相同的，也就是说，列族的个数与名称都是相同的，但是每一行中的每个列族中列的个数可以不同
  - HBase 执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，原有的版本仍然保留
- 特点
  - 稀疏
    - 尽管表中的每一行会拥有相同的列族，但是可能具有截然不同的列。正因为如此，对于整个映射表的每行数据而言，有些列的值就是空的，所以 HBase 的表是稀疏的
  - 多维度
    - 行键、列族、列限定符和时间戳
  - 有序
    - 表的行是按照行键顺序来进行存储的
- 数基本概念
  - 表（Table）
  - 行（Row）
    - 设计行键的一个重要原则就是相关的行键要存储在接近的位置，例如，设计记录网站的表时，行键需要将域名反转（例如，org.apache.www、org.apache.mail、org.apache.jira），这样的设计能使与 apache 相关的域名在表中存储的位置非常接近
  - 列（Column）
    - 列族（Column Family)
    - 列限定符（Column Qualifier）
    - 列族必须在表建立的时候声明，列随时可以新建
  - 单元（Cell）
    - 行键、列族和列限定符一起标识一个单元
  - 时间戳（Timestamp）

- 概念视图
  - 要定位单元中的数据可以采用“三维坐标”来进行，也就是 [行键，列族:列限定符，时间戳]
- 物理视图
  - 在物理存储层面来看，HBase 采用了基于列的存储方式
  - 属于同一个列族的数据保存在一起，同时，和每个列族一起存放的还包括行键和时间戳

#### 29. HBase Shell

- HBase Shell 提供了大多数的 HBase 命令，通过 HBase Shell，用户可以方便地创建、删除及修改表，还可以向表中添加数据，列出表中的相关信息等

#### 30. HBase 主要运行机制

- 物理存储
  - Region
    - HBase 表中的所有行都是按照行键的字典序排列的，当一张表的行太多的时候，HBase 就会根据行键的值对表中的行进行分区，每个行区间构成一个“分区（Region）”，包含了位于某个值域区间内的所有数据
    - Region 是 HBase 中数据分发和负载均衡的最小单元，默认大小是 100MB 到 200MB
    - 不同的 Region 可以分布在不同的 Region Server 上，但一个 Region 不会拆分到多个 Region Server 上。每个 Region Server 负责管理一个 Region 集合
    - Region 是 HBase 在 Region Server 上数据分发的最小单元，但并不是存储的最小单元。事实上，每个 Region  由一个或者多个 Store 组成，每个 Store 保存一个列族的数据
- 逻辑架构
  - 在分布式的生产环境中，HBase 需要运行在 HDFS 之上，以 HDFS 作为其基础的存储设施
  - HBase 的集群主要由 Master、Region Server 和 Zookeeper 组成
  -  Master
    - 主要负责表和 Region 的管理工作
  - Region Server
    - Client 直接与 Region Server 连接，并经过通信获取 HBase 中的数据
    - HBase 釆用 HDFS 作为底层存储文件系统，Region Server 需要向 HDFS 写入数据，并利用 HDFS 提供可靠稳定的数据存储，所以 Region Server 并不需要提供数据复制和维护数据副本的功能
  - Zookeeper
    - 保证了至少有一个 HBase Master 处于运行状态
    - 同时负责管理 Region Server 状态，每个 Region Server 都向 Zookeeper 注册，由 Zookeeper 实时监控每个 Region Server 的状态，并通知给 Master

#### 31. HBase Java API

- HBase 主要包括 5 大类操作
  - HBase 的配置
  - HBase 表的管理
  - 列族的管理
  - 列的管理
  - 数据操作

#### 32. HBase Java 编程实例

- 在本实例中，首先创建一个学生成绩表 scores，用来存储学生各门课程的考试成绩，然后向 scores 添加数据



### 8. MapReduce

#### 33. Hadoop MapReduce

- 批处理模式
  - 由于批处理在应对大量持久数据方面的表现极为出色，因此经常被用于对历史数据进行分析
  - 为了提高处理效率，对大规模数据集进行批处理需要借助分布式并行程序
  - Google 最先实现了分布式并行处理模式 MapReduce，并于 2004 年以论文的方式对外公布了其工作原理，Hadoop MapReduce 是它的开源实现
- 简介
  - 映射（Map)
    - 对集合中的每个元素进行同一个操作
  - 化简（Reduce)
    - 遍历集合中的元素来返回一个综合的结果
- 基本思想
  - 大数据处理思想：分而治之
  - 构建抽象模型：Map 函数和 Reduce 函数
    - MapReduce 定义了 Map 和 Reduce 两个抽象的编程接口，为程序员提供了一个清晰的操作接口抽象描述，由用户去编程实现
  - 上升到架构：并行自动化并隐藏底层细节
    - 任务调度
    - 数据/程序互定位
    - 出错处理
    - 分布式数据存储与文件管理
    - Combiner 和 Partitioner
- Map 函数和 Reduce 函数

| 函数   | 输入          | 输出          | 注解                                                         |
| ------ | ------------- | ------------- | ------------------------------------------------------------ |
| Map    | Map<k1,V1>    | List(<k2,V2>) | 将输入数据集分解成一批<key,value>对，然后进行处理；每一个<key,value>输入，Map 会输出一批<K2,V2> |
| Reduce | <k2,List(V2)> | <K3,V3>       | MapReduce 框架会把 Map 的输出，按 key 归类为 <K2,List(V2)>。List(V2) 是一批属于同一个 K2 的 value |

#### 34. 架构

- 流程
  - 首先把存储在 HDFS 中的输入数据集切分为若干个独立的数据块，由多个 Map 任务（Task）以完全并行的方式处理这些数据块
  - MapReduce 框架会对 Map 任务的输出先进行排序，然后把结果作为输入传送给 Reduce 任务
- 架构
  - JobClient
  - JobTracker
  - TaskTracker
  - Task
- 补充
  - Hadoop MapReduce 框架和 HDFS 是运行在一组相同的结点上的
  - 这种配置允许框架在那些已经存好数据的结点上高效地调度任务

#### 35. 工作流程

- 实际处理过程
  - Input
  - Map
  - Sort
  - Combine
  - Partition
  - Reduce
  - Output
- 补充
  - 在 MapReduce 的整个处理过程中，不同的任务之间不会进行任何通信，用户不能够显式地从一个结点向另一个结点发送消息，所有的信息交换都是通过 MapReduce 框架实现的
  - 如分布式存储、分布式通信、任务调度、容错处理、负载均衡、数据可靠等，这些问题都由 Hadoop MapReduce 框架负责处理，应用开发者只需要负责完成 Map 函数与 Reduce 函数的实现

#### 36. 实例分析

- 单词计数是最简单也是最能体现 MapReduce 思想的程序之一，可以称为 MapReduce 版“Hello World”

#### 37. 工作机制

- 作业执行流程
  1. 提交作业
     - 作业提交之后，就会进入自动化执行。在这个过程中，用户只能监控程序的执行情况和强制中断作业，但是不能对作业的执行过程进行任何干预
  2. 初始化作业
     - 跟踪任务的状态和进程
  3. 分配任务
     - 对于 Map 任务，JobTracker 通常会选取一个距离其输入分片最近的 TaskTracker，对于 Reduce 任务，JobTracker 则无法考虑数据的本地化
  4. 执行任务
     - TaskTracker 启动一个新的 JVM 来运行每个任务（包括 Map 任务和 Reduce 任务），这样，JobClient 的 MapReduce 就不会影响 TaskTracker 守护进程
  5. 进程和状态的更新
     - 一个作业和它的每个任务都有一个状态信息，这些消息通过一定的时间间隔由 ChildJVM 向 TaskTracker 汇聚，然后再向 JobTracker 汇聚
  6. 完成作业
- Shuffle 过程
  - 指从 Map 的输出开始，包括系统执行排序，以及传送 Map 输出到 Reduce 作为输入的过程
  - Map 端的 Shuffle 阶段
    - Map 函数开始产生输出时，并不是简单地把数据写到磁盘中，因为频繁的磁盘操作会导致性能严重下降。它的处理过程是把数据首先写到内存中的一个缓冲区， 并做一些预排序，以提升效率
    - 在写磁盘前，线程首先根据数据最终要传递到的 Reduce 任务把数据划分成相应的分区（Partition）。在每个分区中，后台线程按 Key 进行排序，如果有一个 Combiner，便会在排序后 的输出上运行
    - 在 Map 任务完成前，多个溢出写文件被合并成一个索引文件和数据文件（多路归并排序）（Sort 阶段)
  - Reduce 端的 Shuffle 阶段
    - 将 Map 端复制过来的数据先放入内存缓冲区中， 执行类似于 Map 生成数据的流程（Spill）
    - Reduce 的输入文件已定，整个 Shuffle 阶段就结束了，然后就是 Reduce 执行
- Hadoop MapReduce 的主要特点
  - 向“外”横向扩展，而非向“上”纵向扩展
  - 失效被认为是常态
  - 把处理向数据迁移
  - 顺序处理数据，避免随机访问数据
  - 为应用开发者隐藏系统层细节
  - 平滑无缝的可扩展性

#### 38. 编程实例

- 任务准备
- 编写程序
- 运行代码



## 第四部分 Spark 框架

### 9. Spark 入门

#### 39. 简介

- Hadoop MapRedcue 的缺点
  - 表达能力有限
  - 磁盘 I/O 开销大
  - 计算延迟高

- Spark 的优势
  - 内存计算
  - 模式多样化
  - 更加通用
  - 任务调度机制更优越
- Spark 的劣势
  - 因为 Spark 是基于内存进行数据处理的，所以不适合于数据量特别大、对实时性要求不高的场合
  - Hadoop 可以使用廉价的通用服务器来搭建集群，而 Spark 对硬件要求比较高，特别是对内存和 CPU 有更高的要求

- 大数据处理场景
  - 复杂的批量处理
    - MapReduce
  - 基于历史数据的交互式查询
    - 用 Impala 进行交互式查询
  - 基于实时数据流的数据处理
    - 用 Storm 分布式处理框架处理实时流式数据
- Spark 适用场景
  - 需要多次操作特定数据集的应用场合
  - 数据量不是特别大，但是要求实时统计分析
  - Spark 不适用于那种异步细粒度更新状态的应用

#### 40. RDD

- 基本概念
  - 简介
    - 弹性分布式数据集 (Resiliennt Distributed Datasets)
    - 可以将 RDD 理解为一个分布式对象集合，本质上是一个只读的分区记录集合
    - 一个 RDD 的不同分区可以保存到集群中的不同结点上，从而可以在集群中的不同结点上进行并行计算
    - 实质上是一种更为通用的迭代并行计算框架，用户可以显示控制计算的中间结果，然后将其自由运用于之后的计算
  - 属性
    - 只读
    - 分布式
    - 弹性
    - 基于内存

- 基本操作

  - 构建操作

    1. 从内存里直接读取数据

       - ```scala
         val rdd01 = sc.makeRDD(List(1,2,3,4,5,6))
         ```

    2. 或者文件系统里读取数据

       - ```scala
         val rdd:RDD[String] == sc.textFile("file:///D:/spark-3.0.0-bin-hadoop3.2/README.md",1)
         ```

  - 转换操作（Transformation）

    - 一个 RDD 产生一个新的 RDD
    - 转换出来的 RDD 是惰性求值的，只有在行动操作中用到这些 RDD 时才会被计算

  - 行动操作（Action）

    - 行动操作用于执行计算并按指定的方式输出结果
    - 行动操作接受 RDD，但是返回非 RDD，即输出一个值或者结果

- 血缘关系

  - 描述了一个 RDD 是如何从父 RDD 计算得来的

- 依赖类型

  - 窄依赖
    - 子 RDD 的每个分区依赖于常数个父分区（即与数据规模无关)
    - 输入输出一对一的算子，且结果 RDD 的分区结构不变，如 map、flatMap
    - 输入输出一对一的算子，但结果 RDD 的分区结构发生了变化，如 union
    - 从输入中选择部分元素的算子，如 filter、distinct、subtract、sample
  - 宽依赖
    - 子 RDD 的每个分区依赖于所有父 RDD 分区
    - 对单个 RDD 基于 Key 进行重组和 reduce，如 groupByKey、reduceByKey
    - 对两个 RDD 基于 Key 进行 join 和重组，如 join

- 阶段划分

  - 由于宽依赖会带来“洗牌”，所以不同的 Stage 是不能并行计算的，后面 Stage 的 RDD 的计算需要等待前面 Stage 的 RDD 的所有分区全部计算完毕以后才能进行
  - 把一个 DAG 图划分成多个 Stage 以后，每个 Stage 都代表了一组由关联的、相互之间没有宽依赖关系的任务组成的任务集合。在运行的时候，Spark 会把每个任务集合提交给任务调度器进行处理

- RDD 缓存

  - 如果简单地对 RDD 调用行动操作，Spark 每次都会重算 RDD 及它的依赖，这样就会带来太大的消耗
  - 为了避免多次计算同一个 RDD，可以让 Spark 对数据进行持久化
  - Spark 可以使用 persist 和 cache 方法将任意 RDD 缓存到内存、磁盘文件系统中
    - cache 是 persist 的特例，将该 RDD 缓存到内存中
    - persist 可以让用户根据需求指定一个持久化级别，来决定缓存到内存或者磁盘中
  - 在不使用 cached RDD 的时候，及时使用 unpersist 方法来释放它

#### 41. 总体架构和运行流程

- 总体架构
  - 任务控制结点（Driver）
    - Driver 是运行 Spark Applicaion 的 main() 函数，它会创建 SparkContext
    - SparkContext 负责和 Cluster Manager 通信，进行资源申请、任务分配和监控等
  - 集群资源管理器（Cluster Manager）
    - 负责申请和管理在 Worker Node 上运行应用所需的资源
  - 工作结点（Worker Node）
  - 执行进程（Executor）
    - Executor 是 Application 运行在 Worker Node 上的一个进程，负责运行多个 Task（任务）
    - 与 MapReduce 计算框架相比，Spark 采用的 Executor 具有两大优势
      - Executor 利用多线程来执行具体任务
      - Executor 中有一个 BlockManager 存储模块，会将内存和磁盘共同作为存储设备
- 运行流程
  - 基本流程
    - 启动 SparkContext
    - Cluster Manager 为 Executor 分配资源并启动 Executor 进程
    - DAG Scheduler 构建 DAG 图，并把每个 Stage 的 TaskSet（任务集）发送给 Task Scheduler (任务调度器），Task Scheduler 将 Task 发放给 Executor
    - Task 在 Executor 上运行，把执行结果反馈给 Task Scheduler，然后再反馈给 DAG Scheduler
  - 特点
    - 每个 Application 拥有专属的 Executor 进程，该进程在 Application 运行期间一直驻留，并以多线程方式运行任务
    - Spark 与 Cluster Manager 无关，只要能够获取 Executor 进程，并能保持相互通信即可
    - 在 Spark Application 运行过程中，SparkContext 和 Executor 之间有大量的信息交换
    - Task 采用了数据本地性和推测执行的优化机制
    - Executor 上的 BlockManager（存储模块），可以把内存和磁盘共同作为存储设备

#### 42. Spark 生态圈

- Spark Core 内核
  - 提供了有向无环图（DAG）的分布式并行计算框架，并提供 cache 机制来支持多次迭代计算或者数据共享
  - 在 Spark 中引入了 RDD 的抽象
  - 移动计算而非移动数据
  - 使用多线程池模型来减少 Task 启动开销
  - 采用容错的、高可伸缩性的 Akka 作为通信框架
- Spark Streaming
  - Spark Streaming 是一个对实时数据流进行高通量、容错处理的流式处理系统
- Spark SQL
  - Spark SQL 允许开发人员直接处理 RDD，以及查询存储在 Hive、HBase 上的外部数据
- Spark MLlib
  - 实现了一些常见的机器学习算法和实用程序
- Spark GraphX
  - 用于图并行计算的 API

#### 43. 开发实例

- 通过 Spark Shell
- 通过 Java 应用程序

### 10. Spark Streaming

#### 44. 简介

- Spark Streaming 是 Spark 核心 API 的一个扩展，可以实现高吞吐量的、具备容错机制的实时流数据的处理
- 处理机制
  - 接收实时的输入数据流，并根据一定的时间间隔（如 1 秒）拆分成一批批的数据，然后通过 Spark Engine 处理这些批数据，最终得到处理后的一批批结果数据
- DStream
  - Spark Streaming 支持一个高层的抽象，叫作离散流（Discretized Stream）或者 DStream，它代表连续的数据流
  - 一批数据在 Spark 内核中对应一个 RDD 实例
  - 因此，对应流数据的 DStream 可以看成是一组 RDD，即 RDD 的一个序列

#### 45. 系统架构

- 传统流处理系统架构
  - 故障恢复问题
  - 负载均衡问题
  - 支持统一的流处理与批处理及交互工作的需求
  - 高级分析能力的需求
- Spark Streaming 系统架构
  - Spark Streaming 首先把输入数据按照批段大小（如 1 秒）分成一段一段的数据（DStream），并把每一段数据都转换成 Spark 中的 RDD
  - 然后将 Spark Streaming 中对 DStream 的 Transformation 操作变为 Spark 中对 RDD 的 Transformation 操作，并将操作的中间结果保存在内存中
- 动态负载均衡
  - 传统的流处理系统采用静态方式分配任务给结点
  - 而在 Spark Streaming 中，作业任务将会动态地平衡分配给各个结点
- 容错性
  - 失败的任务可以同时重新在集群结点上并行处理，从而均匀地分布在所有重新计算情况下的众多结点中，这样相比于传统方法能够更快地从故障中恢复过来
- 实时性、扩展性与吞吐量

#### 46. 编程模型

- DStream 的操作流程
  - DStream 由一组时间序列上连续的 RDD 来表示
  - 对 DStream 中数据的各种操作也是映射到内部的 RDD 上来进行
- Spark Streaming 使用
  - 创建 StreamingContext 对象
  - 创建 InputDStream
  - 操作 DStream
  - 启动 Spark Streaming
- 输入源
  - 基础来源
    - 基础来源是在 StreamingContext API 中直接可用的来源，如文件系统、Socket （套接字）等
  - 高级来源
    - 局级来源，如 Kafka、Flume、Kinesis、Twitter 等，可以通过额外的实用工具类来创建

#### 47. 相关操作

- 普通转换操作
  - transform(func)
  - updateStateByKey(fhnc)
- 窗口转换操作
  - 批处理间隔
  - 窗口间隔
  - 滑动间隔
- 输出操作
  - 输出操作实际上使 transformation 操作后的数据可以被外部系统使用，同时输出操作触发所有 DStream 的 transformation 操作的实际执行
  - 注意创建连接对象要在 worker 上，而不是在 driver 上
- 持久化

#### 48. 开发实例

- 流数据模拟器

  - 提供数据源
  - 通过 Socket 方式监听指定的端口号，当外部程序通过该端口进行连接并请求数据时，模拟器将定时将指定的文件数据进行随机获取，并发送给外部程序

- 读取文件演示

  - 监控某目录中的文件，获取在该间隔时间段内变化的数据，然后通过 Spark Streaming 计算出该时间段内的单词统计数

  - ```scala
    val lines = ssc.textFileStream("/home/hadoop/temp/")
    ```

- 网络数据演示

  - 由流数据模拟器以 1 秒的频度发送模拟数据，Spark Streaming 通过 Socket 接收流数据并每 20 秒运行一次来处理接收到的数据，处理完毕后打印该时间段内数据出现的频度，即在各处理段时间内的状态之间并无关系

  - ```scala
    //通过 Socket 获取数据，需要提供 Socket 的主机名和端口号
    val lines = ssc.socketTextStream(args(0),args(1).toInt)
    ```

- Stateful 演示

  - 由流数据模拟器以 1 秒的频度发送模拟数据，Spark Streaming 通过 Socket 接收流数据并每 5 秒运行一次来处理接收到的数据，处理完毕后打印程序启动后单词出现的频度

  - 每次输出的结果不仅仅是统计该时段内接收到的数据，还包括前面所有时段的数据

  - ```scala
    //定义更新状态方法，参数 values 为当前批次单词频度，state 为以往批次单词频度
    val updateFunc = (values: Seq[Int],state: Option[Int]) => {
        val currentCount = values.foldLeft(0)(_ + _)
        val previousCount = state.getOrElse (0)
        Some(currentCount + previousCount)
    }
    val stateDstream = wordCounts.updateStateByKey[Int](updateFunc)
    ```

- 窗口演示

  - 由流数据模拟器以 1 秒的频度发送模拟数据，Spark Streaming 通过 Socket 接收流数据并每 10 秒运行一次来处理接收到的数据，处理完毕后打印程序启动后单词出现的频度

  - ```scala
    //Windows 操作，第一种方式为叠加处理，第二种方式为增量处理
    val windowCounts = wordCounts.reduceByKeyAndWindow(_+_, _-_, windowLength, slideInterval)
    ```



## 第五部分 分析及挖掘

### 11. 数据挖掘

#### 49. 简介

- 基本概念
  - 数据挖掘是从大量的、不完全的、有噪声的、模糊的、随机的实际数据中，提取出蕴涵在其中的，人们事先不知道的，但是具有潜在有用性的信息和知识的过程
  - 一般来讲，数据挖掘的结果并不要求是完全准确的知识，而是发现一种大的趋势
- 价值分类
  - 相关性
  - 趋势
  - 特征
- 常用算法
  - 有监督的学习
    - 分类模型
      - 逻辑回归，决策树
      - KNN，贝叶斯判别
      - SVM，神经网络，随机森林
    - 预测模型
      - 回归分析，回归树
      - 神经网络，SVM
  - 无监督的学习
    - 关联分析
    - 聚类分析
      - k-means 聚类，系谱聚类
      - 密度聚类

#### 50. Spark MLlib

- 简介
  - MLlib 是 Spark 的机器学习库，提供了常用数据挖掘算法的分布式实现功能
- 构成
  - 数据类型
    - 向量、带类别的向量、矩阵等
  - 数学统计计算库
    - 基本统计量、相关分析、随机数产生器、假设检验等
  - 算法评测
    - AUC、准确率、召回率、F-Measure 等
  - 机器学习算法
    - 分类算法、回归算法、聚类算法、协同过滤等
- 优势
  - 基于内存计算
    - 如果迭代时使用 Hadoop MapReduce 计算框架，则每次计算都要读/写磁盘及完成任务的启动等工作，从而会导致非常大的 I/O 和 CPU 消耗
  - Akka 和 Netty 通信系统
    - 通信效率高于 Hadoop MapReduce 计算框架的通信机制

#### 51. 分类和预测

- 简介
  - 分类和预测是两种使用数据进行预测的方式，可用来确定未来的结果
  - 分类是用于预测数据对象的离散类别的，需要预测的属性值是离散的、无序的
  - 预测则是用于预测数据对象的连续取值的，需要预测的属性值是连续的、有序的
- 分类
  - 步骤
    - 训练阶段
    - 评估阶段
- 预测
  - 预测算法所需要预测的属性值是连续的、有序的，分类所需要预测的属性值是离散的、无序的

#### 52. 决策树和朴素贝叶斯算法

- 决策树
  - 简介
    - 树形模型，树中的一个内部结点表示一个特征属性上的测试，对应的分支表示这个特征属性在某个值域上的输出
    - 一个叶子结点存放一个类别，也就是说，带有分类标签的数据集合即为实例所属的分类
    - 用于分类
  - 构建
    - 特征选择
      - 在建立决策树的时候，希望选择的特征能够使分类后的数据集的信息熵尽可能变小，也就是不确定性尽量变小
    - 剪枝
      - 在分类模型建立的过程中，很容易出现过拟合的现象，过拟合时训练误差很小，但是检验误差很大，不利于实际应用
      - 预先剪枝是指，在决策树生长过程中，使用一定条件加以限制，使得在产生完全拟合的决策树之前就停止生长
      - 后剪枝是指，在决策树生长完成之后，按照自底向上的方式修剪决策树
  - 优缺
    - 模型简单，构建速度快，只需要一次构建，就可以反复使用
    - 它对知识的表示是直观的，并且具有描述性，非常容易理解，有助于人工分析
    - 但是决策树的成功应用可能依赖于所拥有的建模数据
- Spark MLlib 决策树算法
  - 简介
    - 支持连续型和离散型的特征变量，也就是既支持预测也支持分类
    - 采用前向剪枝的方法来防止过拟合
  - 使用
    - 训练函数
    - 预测函数
  - 实例

- 朴素贝叶斯算法
  - 简介
    - 对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属 于哪个类别
    - 用于分类
  - 原理
    - P(类别|特征)=P(特征|类别)P(类别)/P(特征)，或者 P(C1|X)=P(X|C1)P(C1)|P(X)
    - 假设每个属性相互独立，则 P(X|C1)=P(X1|C1)P(X2|C1)...(Xn|C1)
  - 优缺
    - 朴素贝叶斯算法的主要优点就是算法逻辑简单，易于实现
    - 同时，分类过程的时空开销小，只会涉及二维存储
    - 但是在属性个数比较多或者属性之间相关性较大时，分类效果不好
- Spark MLlib 朴素贝叶斯算法
  - 简介
  - 实例

#### 53. 回归分析

- 简介
  - 回归分析的基本概念是用一群变量预测另一个变量的方法，目的是找到一个联系输入变量和输出变量的最优模型
  - 用于预测
- 分类
  - 自变量的个数
    - 一元回归分析法
    - 多元回归分析法
  - 因变量的类型
    - 线性回归分析法
    - 非线性回归分析法
  - 回归线的形状
- 线性回归
  - 简介
    - 在线性模型中，因变量是连续型的，自变量可以是连续型或离散型的，回归线是线性的
  - 分类
    - 一元线性回归
    - 多元线性回归
  - 优缺
    - 简单易用
    - 理解和解释都非常直观，还能通过正则化来避免过拟合
    - 但是，线性回归在处理非线性关系时非常糟糕，在识别复杂的模式上也不够灵活
- Spark MLlib 的 SGD 线性回归算法
  - 简介
    - Spark MLlib 的 SGD 线性回归算法是由 LinearRegressionWithSGD 类实现的，该类是基于无正规化的随机梯度下降算法
  - 使用
    - 构造函数
    - 训练函数
  - 实例
- 逻辑回归
  - 简介
    - 改造后的回归分析，用于分类
    - 求解逻辑回归模型参数的常用方法之一是，采用最大似然估计的对数形式构建函数，再利用梯度下降函数来进行求解
  - 优缺
    - 模型比线性回归更简单，好理解，并且实现起来比较方便，特别是大规模线性分类时
    - 缺点是需要大样本量，因为最大似然估计在低样本量的情况下不如最小二乘法有效
    - 而且对模型中自变量的多重共线性较为敏感，需要对自变量进行相关性分析，剔除线性相关的变量，以防止过拟合和欠拟合

#### 54. 聚类分析

- 简介
  - 无监督学习，数据只有特征，没有类别标签
  - 聚类把全体数据实例组织成一些相似组，而这些相似组被称作簇
  - 可以用来发现数据项之间的依赖关系，从而去除或合并有密切依赖关系的数据项
  - 也可以为某些数据挖掘方法（如关联规则、粗糙集方法），提供预处理功能
- 分类
  - 基于划分
    - 基于划分的聚类方法中，最经典的就是k-平均（k-means）算法和 k-中心（k-medoids）算法，很多算法都是由这两个算法改进而来的
    - 优点是，收敛速度快，缺点是，它要求类别数目 k 可以合理地估计，并且初始中心的选择和噪声会对聚类结果产生很大影响
  - 基于层次
    - 简介
      - 基于层次的聚类方法是指对给定的数据进行层次分解，直到满足某种条件为止
      - 距离和规则的相似度容易定义，限制少，不需要预先制定簇的个数，可以发现簇的层次关系
      - 但是，计算复杂度太高，奇异值也能产生很大影响，算法很可能聚类成链状
    - 自底向上法，凝聚式
      - 首先，每个数据对象都是一个簇，计算数据对象之间的距离，每次将距离最近的点合并到同一个簇
      - AGNES (AGglomerative NESing) 算法
    - 自顶向下法，分裂式
      - 该方法在一开始所有个体都属于一个簇，然后逐渐细分为更小的簇
      - DIANA (Divisive ANAlysis) 算法
  - 基于密度
    - 主要目标是寻找被低密度区域分离的高密度区域
    - 基于距离的聚类算法的聚类结果是球状的簇，而基于密度的聚类算法可以发现任意形状的簇
    - DBSAN 算法、OPTICS 算法和 DENCLUE 算法
  - 基于网格
    - 将空间量化为有限数目的单元，可以形成一个网格结构，所有聚类都在网格上进行
    - 处理速度快，其处理时间独立于数据对象数，而仅依赖于量化空间中的每一维的单元数
    - 缺点是只能发现边界是水平或垂直的簇，而不能检测到斜边界
    - 另外，在处理高维数据时，网格单元的数目会随着属性维数的增长而成指数级增长
  - 基于模型
    - 基于模型的聚类方法是试图优化给定的数据和某些数学模型之间的适应性的
    - 这种方法的基本原理就是假定目标数据集是由一系列潜在的概率分布所决定的

#### 55. k-means

- 简介
  - k-means 算法是根据给定的 n 个数据对象的数据集，构建 k 个划分聚类的方法，每个划分聚类即为一个簇
  - 距离函数有明式距离、欧氏距离、马式距离和兰氏距离，最常用的是欧氏距离
- Spark MLlib 中的 k-means 算法
- 优缺点
  - 优点
    - 简单高效，易于理解和实现
    - 算法的时间复杂度低，为O(tkm)，其中，r 为迭代次数，k 为簇的数目，m 为记录数，n 为维数，并且 t<<m k<<n
  - 缺点
    - 需要人为事先确定簇的个数，k 的选择往往会是一个比较困难的问题
    - 对初始值的设置很敏感，算法的结果与初始值的选择有关
    - 对噪声和异常数据非常敏感。如果某个异常值具有很大的数值，则会严重影响数据分布
    - 不能解决非凸形状的数据分布聚类问题
    - 主要用于发现圆形或者球形簇，不能识别非球形的簇

#### 56. DBSCAN

- 简介
  - Density—Based Spatial Clustering of Application with Noise
  - 它将簇定义为密度相连的点的最大集合，能够把具有足够密度的区域划分为簇，并可以在有噪音的空间数据集中发现任意形状的簇
  - DBSCAN 算法的计算复杂的度为 O(n²)，n 为数据对象的数目
- 基本概念
  - 参数
    - Eps 定义密度时的邻域半径
    - MmPts 定义核心点时的阈值
  - 数据点
    - 核心点
    - 边界点
    - 噪音点
- 优缺点
  - 优点
    - 可以对任意形状的稠密数据集进行聚类，而 k-means 之类的聚类算法一般只适用于凸数据集
    - 可以在聚类的同时发现异常点，对数据集中的异常点不敏感
    - 聚类结果没有偏倚，而 k-means 之类的聚类算法的初始值对聚类结果有很大影响
  - 缺点
    - 样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用 DBSCAN 算法一般不适合
    - 样本集较大时，聚类收敛时间较长，此时可以对搜索最近邻时建立的 KD 树或者球树进行规模限制来进行改进
    - 调试参数比较复杂时，主要需要对距离阈值 Eps，邻域样本数阈值 MinPts 进行联合调参，不同的参数组合对最后的聚类效果有较大影响
    - 对于整个数据集只采用了一组参数。如果数据集中存在不同密度的簇或者嵌套簇，则 DBSCAN 算法不能处理。为了解决这个问题，有人提出了 OPTICS 算法
    - DBSCAN 算法可过滤噪声点，这同时也是其缺点，这造成了其不适用于某些领域，如对网络安全领域中恶意攻击的判断

#### 57. 关联分析

- 简介
  - 关联分析是一种简单、实用的分析技术，是指发现存在于大量数据集中的关联性或相关性，从而描述一个事物中某些属性同时岀现的规律和模式
- 基本概念
  - 支持度计数
    - 一个项集出现在几个事务当中，它的支持度计数就是几
  - 支持度
    - 支持度计数除于总的事务数
  - 置信度
    - 对于规则｛A}→{B｝，它的置信度为｛A,B｝的支持度计数除以｛A｝的支持度计数
- 步骤
  - 发现频繁项集
  - 发现关联规则

#### 58. Apriori 和 FP-Tree算法

- Apriori 算法
  - 简介
    - Apriori 算法使用了逐层搜索的迭代方法，即用 k-项集探索（k+1）-项集
    - Apriori 性质
      - 一个频繁项集的所有非空子集也必须是频繁项集。即假如项集 A 不满足最小支持度阈值
      - 即 A 不是频繁的，则如果将项集 B 添加到项集 A 中，那么新项集（AUB）也不可能是频繁的
  - 产生候选项集
    - 蛮力法
    - $F_{k-1}*F_1$ 法
    - $F_{k-1}*F_{k-1}$ 法
  - 优缺
    - Apriori 算法作为经典的频繁项集产生算法，使用先验性质，大大提高了频繁项集逐层产生的效率，它简单易理解，数据集要求低
    - 但是多次扫描事务数据集，需要很大的 I/O 负载
    - 可能产生庞大的候选集
- FP-Tree 算法
  - 简介
    - Frequent Pattern Tree
    - 其思想是构造一棵 FP-Tree，把数据集中的数据映射到树上，再根据这棵 FP-Tree 找出所有频繁项集
    - 克服了 Apriori 算法中存在的问题，在执行效率上也明显好于 Apriori 算法
  - 构造
    - 项头表的建立
    - FP-Tree 的建立
  - 挖掘
- MLlib 的 FP-Growth 算法实例

